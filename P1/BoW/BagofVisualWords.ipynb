{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group 2 Members: Marcos Conde, Jose Manuel Lopez Camu√±as, Alex Martin Martinez"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (4.47.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us first read the train and test files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_filenames = pickle.load(open('train_images_filenames.dat','rb'))\n",
    "test_images_filenames = pickle.load(open('test_images_filenames.dat','rb'))\n",
    "train_images_filenames = ['..' + n[15:] for n in train_images_filenames]\n",
    "test_images_filenames  = ['..' + n[15:] for n in test_images_filenames]\n",
    "\n",
    "train_labels = pickle.load(open('train_labels.dat','rb'))\n",
    "test_labels = pickle.load(open('test_labels.dat','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a SIFT object detector and descriptor. We compute the SIFT descriptors for all the train images and subsequently build a numpy array with all the descriptors stacked together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = cv2.KAZE_create(threshold=0.0001)\n",
    "\n",
    "def get_SIFT_descriptors(detector, x, y):\n",
    "    descriptors = []\n",
    "    label_per_descriptor = []\n",
    "\n",
    "    for filename, labels in zip(x,y):\n",
    "        ima = cv2.imread(filename)\n",
    "        gray = cv2.cvtColor(ima, cv2.COLOR_BGR2GRAY)\n",
    "        kpt, des = detector.detectAndCompute(gray, None)\n",
    "        descriptors.append(des)\n",
    "        label_per_descriptor.append(labels)\n",
    "\n",
    "    descriptors_np = np.vstack(descriptors)\n",
    "\n",
    "    return descriptors_np, descriptors, label_per_descriptor\n",
    "\n",
    "train_descriptors_np, train_descriptors, train_label_per_descriptor = get_SIFT_descriptors(detector, train_images_filenames, train_labels)\n",
    "test_descriptors_np, test_descriptors, test_label_per_descriptor = get_SIFT_descriptors(detector, test_images_filenames, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now compute a k-means clustering on the descriptor space and, for each train image, we project each keypoint descriptor to its closest visual word. We represent each of the images with the frequency of each visual word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 128\n",
    "codebook = MiniBatchKMeans(n_clusters=k, verbose=False, batch_size=k * 20,compute_labels=False,reassignment_ratio=10**-4,random_state=42)\n",
    "\n",
    "def get_visual_words(descriptors,descriptors_np,codebook,k,test=False):\n",
    "    \n",
    "    if not test:\n",
    "        codebook.fit(descriptors_np)\n",
    "        \n",
    "    visual_words = np.zeros((len(descriptors), k), dtype=np.float32)\n",
    "    \n",
    "    for i in range(len(descriptors)):\n",
    "        words = codebook.predict(descriptors[i])\n",
    "        visual_words[i,:] = np.bincount(words, minlength=k)\n",
    "    \n",
    "    return words, visual_words\n",
    "\n",
    "words_train, visual_words_train = get_visual_words(train_descriptors,train_descriptors_np,codebook,k)\n",
    "words_test, visual_words_test = get_visual_words(test_descriptors,test_descriptors_np,codebook,k,test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1,2,3,4,5])\n",
    "b = np.array([6,7,8,9,10])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " We build a k-nn classifier, train it with the train descriptors and computing the test descriptors and compute the accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57.42049530511069"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evaluate_knn(visual_words_train, visual_words_test,n_neighbors=5, metric='euclidean', cross_val = True):\n",
    "    if not cross_val:\n",
    "        knn = KNeighborsClassifier(n_neighbors=n_neighbors,n_jobs=-1,metric=metric)\n",
    "        knn.fit(visual_words_train, train_labels) \n",
    "        accuracy = 100*knn.score(visual_words_test, test_labels)\n",
    "        return accuracy\n",
    "    \n",
    "    kf = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "    accuracy = 0\n",
    "    \n",
    "    for train_index, test_index in kf.split(visual_words_train):\n",
    "        X_train, X_test = visual_words_train[train_index], visual_words_train[test_index]\n",
    "        y_train, y_test = np.array(train_labels)[train_index.astype(int)], np.array(train_labels)[test_index.astype(int)]\n",
    "        \n",
    "        X_test, y_test = np.concatenate((X_test,visual_words_test)), np.concatenate((y_test,test_labels))\n",
    "        \n",
    "        knn = KNeighborsClassifier(n_neighbors=n_neighbors,n_jobs=-1,metric=metric)\n",
    "        knn.fit(X_train, y_train)\n",
    "        \n",
    "        accuracy += 100*knn.score(X_test, y_test)\n",
    "    \n",
    "    return accuracy/5\n",
    "        \n",
    "        \n",
    "evaluate_knn(visual_words_train, visual_words_test, n_neighbors=5, metric='euclidean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dimensionality reduction, with PCA and LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57.82627196088735"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evaluate_pca(visual_words_train, visual_words_test,n_components=64,n_neighbors=5,metric='euclidean', cross_val = True):\n",
    "    if not cross_val:\n",
    "        pca = PCA(n_components=n_components)\n",
    "        VWpca = pca.fit_transform(visual_words_train)\n",
    "        knnpca = KNeighborsClassifier(n_neighbors=n_neighbors,n_jobs=-1,metric=metric)\n",
    "        knnpca.fit(VWpca, train_labels) \n",
    "        vwtestpca = pca.transform(visual_words_test)\n",
    "        accuracy = 100*knnpca.score(vwtestpca, test_labels)\n",
    "        return accuracy\n",
    "    \n",
    "    kf = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "    accuracy = 0\n",
    "    \n",
    "    for train_index, test_index in kf.split(visual_words_train):\n",
    "        X_train, X_test = visual_words_train[train_index], visual_words_train[test_index]\n",
    "        y_train, y_test = np.array(train_labels)[train_index.astype(int)], np.array(train_labels)[test_index.astype(int)]   \n",
    "        X_test, y_test = np.concatenate((X_test,visual_words_test)), np.concatenate((y_test,test_labels))\n",
    "        pca = PCA(n_components=n_components)\n",
    "        VWpca = pca.fit_transform(X_train)\n",
    "        knnpca = KNeighborsClassifier(n_neighbors=n_neighbors,n_jobs=-1,metric=metric)\n",
    "        knnpca.fit(VWpca, y_train)\n",
    "        vwtestpca = pca.transform(X_test)\n",
    "        accuracy += 100*knnpca.score(vwtestpca, y_test)\n",
    "        \n",
    "    \n",
    "    return accuracy/5\n",
    "\n",
    "evaluate_pca(visual_words_train, visual_words_test,n_components=64,n_neighbors=5,metric='euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63.79300792762331"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def evaluate_lda(visual_words_train, visual_words_test,n_components=7,n_neighbors=5,metric='euclidean', cross_val = True):\n",
    "    if not cross_val:\n",
    "        lda = LinearDiscriminantAnalysis(n_components=n_components)\n",
    "        VWlda = lda.fit_transform(visual_words_train,train_labels)\n",
    "        knnlda = KNeighborsClassifier(n_neighbors=5,n_jobs=-1,metric='euclidean')\n",
    "        knnlda.fit(VWlda, train_labels) \n",
    "        vwtestlda = lda.transform(visual_words_test)\n",
    "        accuracy = 100*knnlda.score(vwtestlda, test_labels)\n",
    "        return accuracy\n",
    "    \n",
    "    kf = KFold(n_splits=5, random_state=42, shuffle=True)\n",
    "    accuracy = 0\n",
    "    \n",
    "    for train_index, test_index in kf.split(visual_words_train):\n",
    "        X_train, X_test = visual_words_train[train_index], visual_words_train[test_index]\n",
    "        y_train, y_test = np.array(train_labels)[train_index.astype(int)], np.array(train_labels)[test_index.astype(int)]   \n",
    "        X_test, y_test = np.concatenate((X_test,visual_words_test)), np.concatenate((y_test,test_labels))\n",
    "        lda = LinearDiscriminantAnalysis(n_components=n_components)\n",
    "        VWlda = lda.fit_transform(X_train ,y_train)\n",
    "        knnlda = KNeighborsClassifier(n_neighbors=n_neighbors,n_jobs=-1,metric=metric)\n",
    "        knnlda.fit(VWlda, y_train)\n",
    "        vwtestlda = lda.transform(X_test)\n",
    "        accuracy += 100*knnlda.score(vwtestlda, y_test)\n",
    "        \n",
    "    \n",
    "    return accuracy/5\n",
    "    \n",
    "evaluate_lda(visual_words_train, visual_words_test,n_components=7,n_neighbors=5,metric='euclidean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIFT with different amount of local features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating SIFT with 100 features\n",
      "--------------------------------------------------\n",
      "Evaluating SIFT with 500 features\n",
      "--------------------------------------------------\n",
      "Evaluating SIFT with 1000 features\n",
      "--------------------------------------------------\n",
      "Evaluating SIFT with 2500 features\n",
      "--------------------------------------------------\n",
      "Evaluating SIFT with 5000 features\n",
      "--------------------------------------------------\n",
      "Evaluating SIFT with 10000 features\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def evaluate_SIFT(nfeatures=1000,k=128):\n",
    "    print(\"Evaluating SIFT with {} features\".format(nfeatures))\n",
    "    print(50*\"-\")\n",
    "    detector = cv2.xfeatures2d.SIFT_create(nfeatures=nfeatures)\n",
    "    train_descriptors_np, train_descriptors, train_label_per_descriptor = get_SIFT_descriptors(detector, train_images_filenames, train_labels)\n",
    "    test_descriptors_np, test_descriptors, test_label_per_descriptor = get_SIFT_descriptors(detector, test_images_filenames, test_labels)\n",
    "\n",
    "    words_train, visual_words_train = get_visual_words(train_descriptors,train_descriptors_np,codebook,k)\n",
    "    words_test, visual_words_test = get_visual_words(test_descriptors,test_descriptors_np,codebook,k,test=True)\n",
    "\n",
    "    knn_acc = evaluate_knn(visual_words_train, visual_words_test, n_neighbors=5, metric='euclidean')\n",
    "    pca_acc = evaluate_pca(visual_words_train, visual_words_test, n_components=64,n_neighbors=5,metric='euclidean')\n",
    "    lda_acc = evaluate_lda(visual_words_train, visual_words_test, n_components=7,n_neighbors=5,metric='euclidean')\n",
    "    return [knn_acc,pca_acc,lda_acc]\n",
    "    \n",
    "\n",
    "\n",
    "opt = [100, 500, 1000, 2500, 5000, 10000]\n",
    "\n",
    "results = {}\n",
    "\n",
    "for n in opt:   \n",
    "    results[str(n)+\" features\"] = evaluate_SIFT(nfeatures=n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KNN</th>\n",
       "      <th>KNN-PCA</th>\n",
       "      <th>KNN-LDA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100 features</th>\n",
       "      <td>40.720240</td>\n",
       "      <td>37.609776</td>\n",
       "      <td>46.348681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500 features</th>\n",
       "      <td>57.150082</td>\n",
       "      <td>58.181259</td>\n",
       "      <td>60.851734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000 features</th>\n",
       "      <td>57.538639</td>\n",
       "      <td>59.229056</td>\n",
       "      <td>61.629461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2500 features</th>\n",
       "      <td>58.569872</td>\n",
       "      <td>59.415181</td>\n",
       "      <td>61.341899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5000 features</th>\n",
       "      <td>58.569872</td>\n",
       "      <td>59.263139</td>\n",
       "      <td>61.341899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000 features</th>\n",
       "      <td>58.569872</td>\n",
       "      <td>59.043331</td>\n",
       "      <td>61.341899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      KNN    KNN-PCA    KNN-LDA\n",
       "100 features    40.720240  37.609776  46.348681\n",
       "500 features    57.150082  58.181259  60.851734\n",
       "1000 features   57.538639  59.229056  61.629461\n",
       "2500 features   58.569872  59.415181  61.341899\n",
       "5000 features   58.569872  59.263139  61.341899\n",
       "10000 features  58.569872  59.043331  61.341899"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.DataFrame.from_dict(results, orient='index')\n",
    "df.columns = [\"KNN\", \"KNN-PCA\", \"KNN-LDA\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x183d58e7e20>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.plot(kind=\"bar\",figsize=(10,10), rot=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When augmenting the number of features used to produce de BoVW we obtain better results overall until a certain precission is reached when using more features doesn't get better precission. In the case of KNN used with PCA we can observe that the precission even get worse when using more features as it may be reducing the dimensionality of the feature space using directions that are not useful to the clasification. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try Dense SIFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dense_SIFT_features(images, lbls, nfeatures=5000):\n",
    "    descriptors = []\n",
    "    label_per_descriptor = []\n",
    "    descriptors_np = None\n",
    "    sift = cv2.xfeatures2d.SIFT_create(nfeatures=nfeatures)\n",
    "    \n",
    "    for filename, labels in zip(images,lbls):\n",
    "        ima = cv2.imread(filename)\n",
    "        gray = cv2.cvtColor(ima, cv2.COLOR_BGR2GRAY)\n",
    "        step_size = 5\n",
    "        kp = [cv2.KeyPoint(x, y, step_size) for y in range(0, gray.shape[0], step_size) \n",
    "                                        for x in range(0, gray.shape[1], step_size)]\n",
    "        \n",
    "        kp, des = sift.compute(gray, kp)\n",
    "        descriptors.append(des)\n",
    "        label_per_descriptor.append(labels)\n",
    "    \n",
    "    descriptors_np = np.vstack(descriptors)\n",
    "\n",
    "    \n",
    "    return descriptors_np, descriptors, label_per_descriptor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_dense_SIFT(nfeatures=5000, k=128):\n",
    "    print(\"Evaluating Dense SIFT with {} features\".format(nfeatures))\n",
    "    print(50*\"-\")\n",
    "    train_descriptors_np, train_descriptors, train_label_per_descriptor = get_dense_SIFT_features(train_images_filenames, train_labels, nfeatures)\n",
    "    test_descriptors_np, test_descriptors, test_label_per_descriptor = get_dense_SIFT_features(test_images_filenames, test_labels, nfeatures)\n",
    "\n",
    "    words_train, visual_words_train = get_visual_words(train_descriptors,train_descriptors_np,codebook,k)\n",
    "    words_test, visual_words_test = get_visual_words(test_descriptors,test_descriptors_np,codebook,k,test=True)\n",
    "\n",
    "    knn_acc = evaluate_knn(visual_words_train, visual_words_test, n_neighbors=5, metric='euclidean')\n",
    "    pca_acc = evaluate_pca(visual_words_train, visual_words_test, n_components=64,n_neighbors=5,metric='euclidean')\n",
    "    lda_acc = evaluate_lda(visual_words_train, visual_words_test, n_components=7,n_neighbors=5,metric='euclidean')\n",
    "    return [knn_acc,pca_acc,lda_acc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Dense SIFT with 5000 features\n",
      "--------------------------------------------------\n",
      "Evaluating SIFT with 5000 features\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>KNN</th>\n",
       "      <th>KNN-PCA</th>\n",
       "      <th>KNN-LDA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Dense SIFT</th>\n",
       "      <td>70.554477</td>\n",
       "      <td>70.858674</td>\n",
       "      <td>79.394748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SIFT</th>\n",
       "      <td>58.569872</td>\n",
       "      <td>59.043416</td>\n",
       "      <td>61.341899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  KNN    KNN-PCA    KNN-LDA\n",
       "Dense SIFT  70.554477  70.858674  79.394748\n",
       "SIFT        58.569872  59.043416  61.341899"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_keys = [\"Dense SIFT\", \"SIFT\"]\n",
    "results_list = [evaluate_dense_SIFT(nfeatures=5000), evaluate_SIFT(nfeatures=5000)]\n",
    "results = dict(zip(results_keys,results_list))\n",
    "df = pd.DataFrame.from_dict(results, orient='index')\n",
    "df.columns = [\"KNN\", \"KNN-PCA\", \"KNN-LDA\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x183d5bc1940>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.plot(kind=\"bar\",figsize=(10,10), rot=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using Dense sift we can observe significant better results at all the methods tested. Using local features obtained with a certain regularity in the image improves the performance of the BoVW. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different codebook k sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating SIFT with 5000 features and k=32\n",
      "--------------------------------------------------\n",
      "Evaluating SIFT with 5000 features and k=64\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3343, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-17-9b0de05f79dc>\", line 24, in <module>\n",
      "    results[\"k = \"+str(n)] = evaluate_SIFT_k_codebook(nfeatures=5000, k=n)\n",
      "  File \"<ipython-input-17-9b0de05f79dc>\", line 7, in evaluate_SIFT_k_codebook\n",
      "    test_descriptors_np, test_descriptors, test_label_per_descriptor = get_SIFT_descriptors(detector, test_images_filenames, test_labels)\n",
      "  File \"<ipython-input-4-f897c5a3f835>\", line 10, in get_SIFT_descriptors\n",
      "    kpt, des = detector.detectAndCompute(gray, None)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1169, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\inspect.py\", line 1503, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\inspect.py\", line 1461, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\inspect.py\", line 708, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\inspect.py\", line 744, in getmodule\n",
      "    for modname, module in sys.modules.copy().items():\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-9b0de05f79dc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mopt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"k = \"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate_SIFT_k_codebook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnfeatures\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-17-9b0de05f79dc>\u001b[0m in \u001b[0;36mevaluate_SIFT_k_codebook\u001b[1;34m(nfeatures, k)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mtrain_descriptors_np\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_descriptors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_label_per_descriptor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_SIFT_descriptors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdetector\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_images_filenames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mtest_descriptors_np\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_descriptors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_label_per_descriptor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_SIFT_descriptors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdetector\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_images_filenames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-f897c5a3f835>\u001b[0m in \u001b[0;36mget_SIFT_descriptors\u001b[1;34m(detector, x, y)\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mgray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mima\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mkpt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdetector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetectAndCompute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0mdescriptors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2043\u001b[0m                         \u001b[1;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2044\u001b[1;33m                         \u001b[0mstb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2045\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[1;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[0;32m   2044\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2045\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2046\u001b[1;33m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[0;32m   2047\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[0;32m   2048\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1433\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1434\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1435\u001b[1;33m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[0;32m   1436\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0;32m   1437\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1333\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1334\u001b[0m             \u001b[1;31m# Verbose modes need a full traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1335\u001b[1;33m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[0;32m   1336\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1337\u001b[0m             )\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1190\u001b[0m         \u001b[1;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1192\u001b[1;33m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[0;32m   1193\u001b[0m                                                                tb_offset)\n\u001b[0;32m   1194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[1;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[0;32m   1148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1149\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1150\u001b[1;33m         \u001b[0mlast_unique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1152\u001b[0m         \u001b[0mframes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[1;34m(etype, value, records)\u001b[0m\n\u001b[0;32m    449\u001b[0m     \u001b[1;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 451\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    452\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m     \u001b[1;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "def evaluate_SIFT_k_codebook(nfeatures=5000,k=128):\n",
    "    print(\"Evaluating SIFT with {} features and k={}\".format(nfeatures,k))\n",
    "    print(50*\"-\")\n",
    "    codebook = MiniBatchKMeans(n_clusters=k, verbose=False, batch_size=k * 20,compute_labels=False,reassignment_ratio=10**-4,random_state=42)\n",
    "    detector = cv2.xfeatures2d.SIFT_create(nfeatures=nfeatures)\n",
    "    train_descriptors_np, train_descriptors, train_label_per_descriptor = get_SIFT_descriptors(detector, train_images_filenames, train_labels)\n",
    "    test_descriptors_np, test_descriptors, test_label_per_descriptor = get_SIFT_descriptors(detector, test_images_filenames, test_labels)\n",
    "\n",
    "    words_train, visual_words_train = get_visual_words(train_descriptors,train_descriptors_np,codebook,k)\n",
    "    words_test, visual_words_test = get_visual_words(test_descriptors,test_descriptors_np,codebook,k,test=True)\n",
    "\n",
    "    knn_acc = evaluate_knn(visual_words_train, visual_words_test, n_neighbors=5, metric='euclidean')\n",
    "    pca_acc = evaluate_pca(visual_words_train, visual_words_test, n_components=int(k/2),n_neighbors=5,metric='euclidean')\n",
    "    lda_acc = evaluate_lda(visual_words_train, visual_words_test, n_components=7,n_neighbors=5,metric='euclidean')\n",
    "    return [knn_acc,pca_acc,lda_acc]\n",
    "    \n",
    "\n",
    "\n",
    "opt = [32, 64, 128, 256, 512, 1024]\n",
    "\n",
    "results = {}\n",
    "\n",
    "for n in opt:   \n",
    "    results[\"k = \"+str(n)] = evaluate_SIFT_k_codebook(nfeatures=5000, k=n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(results, orient='index')\n",
    "df.columns = [\"KNN\", \"KNN-PCA\", \"KNN-LDA\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(kind=\"bar\",figsize=(10,10), rot=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When varying the codebook sizes the number of bins used to produce the histograms changes. In this test we observe that for the three methods when 128 was used as the codebook size the results were better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different N_Neighbors for KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_SIFT_n_neighbors(nfeatures=5000,k=128,n_neighbors=5):\n",
    "    print(\"Evaluating SIFT with {} features and k={} and n_neighbors={}\".format(nfeatures,k, n_neighbors))\n",
    "    print(50*\"-\")\n",
    "    codebook = MiniBatchKMeans(n_clusters=k, verbose=False, batch_size=k * 20,compute_labels=False,reassignment_ratio=10**-4,random_state=42)\n",
    "    detector = cv2.xfeatures2d.SIFT_create(nfeatures=nfeatures)\n",
    "    train_descriptors_np, train_descriptors, train_label_per_descriptor = get_SIFT_descriptors(detector, train_images_filenames, train_labels)\n",
    "    test_descriptors_np, test_descriptors, test_label_per_descriptor = get_SIFT_descriptors(detector, test_images_filenames, test_labels)\n",
    "\n",
    "    words_train, visual_words_train = get_visual_words(train_descriptors,train_descriptors_np,codebook,k)\n",
    "    words_test, visual_words_test = get_visual_words(test_descriptors,test_descriptors_np,codebook,k,test=True)\n",
    "\n",
    "    knn_acc = evaluate_knn(visual_words_train, visual_words_test, n_neighbors=n_neighbors, metric='euclidean')\n",
    "    pca_acc = evaluate_pca(visual_words_train, visual_words_test, n_components=int(k/2),n_neighbors=n_neighbors,metric='euclidean')\n",
    "    lda_acc = evaluate_lda(visual_words_train, visual_words_test, n_components=7,n_neighbors=n_neighbors,metric='euclidean')\n",
    "    return [knn_acc,pca_acc,lda_acc]\n",
    "    \n",
    "\n",
    "\n",
    "opt = [2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "\n",
    "results = {}\n",
    "\n",
    "for n in opt:   \n",
    "    results[\"n = \"+str(n)] = evaluate_SIFT_n_neighbors(nfeatures=5000, k=128, n_neighbors=n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(results, orient='index')\n",
    "df.columns = [\"KNN\", \"KNN-PCA\", \"KNN-LDA\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(kind=\"bar\",figsize=(10,10), rot=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When varying this parameter we can observe that the perform of all the methods gets better as the number of neighbours taken into account to determine the label of the image is bigger. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different Metrics for KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_SIFT_knn_metric(nfeatures=5000,k=128,n_neighbors=5, metric=\"euclidean\", cross_val=True):\n",
    "    print(\"Evaluating SIFT with {} features and k={} and n_neighbors={} and metric={}\".format(nfeatures,k, n_neighbors, metric))\n",
    "    print(50*\"-\")\n",
    "    codebook = MiniBatchKMeans(n_clusters=k, verbose=False, batch_size=k * 20,compute_labels=False,reassignment_ratio=10**-4,random_state=42)\n",
    "    detector = cv2.xfeatures2d.SIFT_create(nfeatures=nfeatures)\n",
    "    train_descriptors_np, train_descriptors, train_label_per_descriptor = get_SIFT_descriptors(detector, train_images_filenames, train_labels)\n",
    "    test_descriptors_np, test_descriptors, test_label_per_descriptor = get_SIFT_descriptors(detector, test_images_filenames, test_labels)\n",
    "\n",
    "    words_train, visual_words_train = get_visual_words(train_descriptors,train_descriptors_np,codebook,k)\n",
    "    words_test, visual_words_test = get_visual_words(test_descriptors,test_descriptors_np,codebook,k,test=True)\n",
    "\n",
    "    knn_acc = evaluate_knn(visual_words_train, visual_words_test, n_neighbors=n_neighbors, metric=metric, cross_val=cross_val)\n",
    "    pca_acc = evaluate_pca(visual_words_train, visual_words_test, n_components=int(k/2),n_neighbors=n_neighbors,metric=metric, cross_val=cross_val)\n",
    "    lda_acc = evaluate_lda(visual_words_train, visual_words_test, n_components=7,n_neighbors=n_neighbors,metric=metric, cross_val=cross_val)\n",
    "    return [knn_acc,pca_acc,lda_acc]\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "cross_val = True\n",
    "opt = [\"euclidean\",\"manhattan\",\"chebyshev\",\"minkowski\",\"seuclidean\",\"mahalanobis\"]\n",
    "\n",
    "if cross_val:\n",
    "    opt.remove(\"seuclidean\")\n",
    "    opt.remove(\"mahalanobis\")\n",
    "\n",
    "results = {}\n",
    "\n",
    "for n in opt:   \n",
    "    results[str(n)] = evaluate_SIFT_knn_metric(nfeatures=5000, k=128, n_neighbors=5, metric=n, cross_val=cross_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(results, orient='index')\n",
    "df.columns = [\"KNN\", \"KNN-PCA\", \"KNN-LDA\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(kind=\"bar\",figsize=(10,10), rot=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The methods perform differently depending on the metric used to determine the distance of the features. Euclidean and minkowski metrics are the best ones and have very similar performances in the three methods. When using the chebyshev metric the results get significantly worse with the KNN without any reduction of the dimensions being the most affected by it. On the other hand KNN with LDA doesn't vary a lot from the rest of the metrics. For the KNN with PCA the manhattan and chebyshev metrics get worse results. The metric changes how the distance between the points at the feature space are being calculated woth respect to the point to be labelled. This affects directly to which points will be the closest to the points to be classified and affects the final result.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reducing Dimensionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_SIFT_dimensionality(nfeatures=5000,k=128,n_neighbors=5, metric=\"euclidean\", pca=64, lda=7, cross_val=True):\n",
    "    print(\"Evaluating SIFT with {} features and k={} and n_neighbors={} and metric={} and pca={} and lda={}\".format(nfeatures,k, n_neighbors, metric, pca, lda))\n",
    "    print(50*\"-\")\n",
    "    codebook = MiniBatchKMeans(n_clusters=k, verbose=False, batch_size=k * 20,compute_labels=False,reassignment_ratio=10**-4,random_state=42)\n",
    "    detector = cv2.xfeatures2d.SIFT_create(nfeatures=nfeatures)\n",
    "    train_descriptors_np, train_descriptors, train_label_per_descriptor = get_SIFT_descriptors(detector, train_images_filenames, train_labels)\n",
    "    test_descriptors_np, test_descriptors, test_label_per_descriptor = get_SIFT_descriptors(detector, test_images_filenames, test_labels)\n",
    "\n",
    "    words_train, visual_words_train = get_visual_words(train_descriptors,train_descriptors_np,codebook,k)\n",
    "    words_test, visual_words_test = get_visual_words(test_descriptors,test_descriptors_np,codebook,k,test=True)\n",
    "\n",
    "    pca_acc = evaluate_pca(visual_words_train, visual_words_test, n_components=int(pca),n_neighbors=n_neighbors,metric=metric,cross_val=cross_val)\n",
    "    lda_acc = evaluate_lda(visual_words_train, visual_words_test, n_components=int(lda),n_neighbors=n_neighbors,metric=metric,cross_val=cross_val)\n",
    "    return [pca_acc,lda_acc]\n",
    "    \n",
    "\n",
    "\n",
    "cross_val = True\n",
    "opt = [(8,3),(16, 5),(32, 7),(64, 9),(96, 11), (128, 13)]\n",
    "\n",
    "if cross_val:\n",
    "    opt = opt[:-3]\n",
    "\n",
    "results = {}\n",
    "\n",
    "for n1,n2 in opt:   \n",
    "    results[\"pca=\"+str(n1)+\" lda=\"+str(n2)] = evaluate_SIFT_dimensionality(nfeatures=5000,k=128, n_neighbors=5, metric=\"euclidean\", pca=n1, lda=n2, cross_val=cross_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(results, orient='index')\n",
    "df.columns = [\"KNN-PCA\", \"KNN-LDA\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot(kind=\"bar\", figsize=(10,10), rot=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At both methods we can observe that performing a dimension reduction that uses not enough dimensions can have a negative impact in the performance. As too few dimensions are being used the algorithms are not capable to keep the important information to produce the label classification afterwards. "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c4510ae2205fc661e79c1256e94d74e13c5222290d1a25941673cb48af3ea7c0"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

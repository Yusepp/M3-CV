{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Week 5: Building our CNN**\n",
    "### José Manuel López, Alex Martín, Marcos V. Conde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import os\n",
    "import numpy as np\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.python.util import deprecation\n",
    "from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "from tensorflow.python.client import device_lib\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Conv2D, GlobalAveragePooling2D, MaxPooling2D, Dropout, BatchNormalization, Input\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Data and TF/Keras GPU setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR_SMALL = \"./datasets/MIT_small_train_{}\"\n",
    "DATA_DIR_BIG = \"./datasets/MIT_split\"\n",
    "IMG_SIZE = 64\n",
    "BATCH_SIZE = 128\n",
    "RANDOM_SEED = 42\n",
    "CLASSES = ['coast','forest','highway','inside_city','mountain','Opencountry','street','tallbuilding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:26:00.0, compute capability: 8.6\n",
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 3080, compute capability 8.6\n",
      "PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
      "2.6.0\n"
     ]
    }
   ],
   "source": [
    "# Disable Warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "# VRAM broke without this\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "deprecation._PRINT_DEPRECATION_WARNINGS = False\n",
    "tf.config.experimental_run_functions_eagerly(True)\n",
    "\n",
    "try:\n",
    "    # print model to see if it's compatible with Mixed Precision\n",
    "    print(device_lib.list_local_devices()[1].physical_device_desc)\n",
    "    # Change to TF16 mixed precision\n",
    "    policy = mixed_precision.Policy('mixed_float16')\n",
    "    mixed_precision.set_policy(policy)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "print(gpus[0])\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(path, aug):\n",
    "    print(\"Loading: {}\".format(path))\n",
    "    if not aug:\n",
    "        train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "        test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "        train_loader = train_datagen.flow_from_directory(\n",
    "                path+'/train',  \n",
    "                target_size=(IMG_SIZE, IMG_SIZE), \n",
    "                batch_size=BATCH_SIZE,\n",
    "                classes = CLASSES,\n",
    "                class_mode='categorical') \n",
    "\n",
    "        test_loader = test_datagen.flow_from_directory(\n",
    "            path+'/test',\n",
    "            target_size=(IMG_SIZE, IMG_SIZE),\n",
    "            batch_size=BATCH_SIZE,\n",
    "            classes = CLASSES,\n",
    "            class_mode='categorical')\n",
    "        \n",
    "        return train_loader, test_loader\n",
    "        \n",
    "    else:\n",
    "\n",
    "        train_datagen = ImageDataGenerator(rescale=1./255, featurewise_center = False, samplewise_center = False,\n",
    "                                           featurewise_std_normalization = False, samplewise_std_normalization = False,\n",
    "                                           rotation_range = 0.2, width_shift_range = 15, height_shift_range = 15, shear_range = 0.2,\n",
    "                                           zoom_range = 0.2, fill_mode = \"nearest\", horizontal_flip = True\n",
    "                                            )\n",
    "        test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "        train_loader = train_datagen.flow_from_directory(\n",
    "                path+'/train',  \n",
    "                target_size=(IMG_SIZE, IMG_SIZE), \n",
    "                batch_size=BATCH_SIZE,\n",
    "                classes = CLASSES,\n",
    "                class_mode='categorical') \n",
    "\n",
    "        test_loader = test_datagen.flow_from_directory(\n",
    "            path+'/test',\n",
    "            target_size=(IMG_SIZE, IMG_SIZE),\n",
    "            batch_size=BATCH_SIZE,\n",
    "            classes = CLASSES,\n",
    "            class_mode='categorical')\n",
    "        \n",
    "        return train_loader, test_loader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: ./datasets/MIT_small_train_1\n",
      "Found 400 images belonging to 8 classes.\n",
      "Found 2288 images belonging to 8 classes.\n",
      "Loading: ./datasets/MIT_split\n",
      "Found 1881 images belonging to 8 classes.\n",
      "Found 807 images belonging to 8 classes.\n",
      "Data Shape: (128, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "train_small, test_small = get_dataset(DATA_DIR_SMALL.format(1), aug = True)\n",
    "train_big, test_big = get_dataset(DATA_DIR_BIG, aug = True)\n",
    "\n",
    "\n",
    "examples = enumerate(train_big)\n",
    "batch_idx, (example_data, example_targets) = next(examples)\n",
    "print(\"Data Shape: {}\".format(example_data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building Model and Plotting Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(n_conv = 4, kernel_size = 5, conv = 256, n_dense = 2, dense = 1024, max_pool = False, dropout = False, batch_norm = False, opt = \"adam\"):\n",
    "    #create model\n",
    "    model = Sequential()\n",
    "    #add model layers\n",
    "    for idx, i in enumerate(range(n_conv)):\n",
    "        if idx == 0:\n",
    "            model.add(Conv2D(conv, kernel_size=kernel_size, activation=\"relu\", input_shape=(IMG_SIZE,IMG_SIZE,3)))\n",
    "            \n",
    "            if max_pool:\n",
    "                model.add(MaxPooling2D())\n",
    "        else:\n",
    "            model.add(Conv2D(conv, kernel_size=kernel_size, activation=\"relu\"))\n",
    "        \n",
    "        if batch_norm:\n",
    "            model.add(BatchNormalization())\n",
    "\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "\n",
    "    for i in range(n_dense):\n",
    "        model.add(Dense(dense, activation=\"relu\"))\n",
    "        if dropout:\n",
    "            model.add(Dropout(0.2))\n",
    "        \n",
    "        if batch_norm:\n",
    "            model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Dense(len(CLASSES), activation=\"softmax\"))\n",
    "\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy',metrics=[\"accuracy\"])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def plot_loss_accuracy(history, title):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(25,8))\n",
    "    \n",
    "    fig.suptitle(title, fontsize=16)\n",
    "\n",
    "    # Plot history: CrossEntropy\n",
    "    ax1.plot(history.history['loss'], label='CrossEntropy (training data)')\n",
    "    ax1.plot(history.history['val_loss'], label='CrossEntropy (validation data)')\n",
    "    ax1.set_title('Loss Function: Cross Entropy')\n",
    "    ax1.set(xlabel='Epoch', ylabel='Loss Value')\n",
    "    ax1.legend(loc=\"upper left\")\n",
    "\n",
    "    # Plot history: Accuracy\n",
    "    ax2.plot(history.history['accuracy'], label='Accuracy (training data)')\n",
    "    ax2.plot(history.history['val_accuracy'], label='Accuracy (validation data)')\n",
    "    ax2.set_title('Accuracy')\n",
    "    ax2.set(xlabel='Epoch', ylabel='Accuracy Value')\n",
    "    ax2.legend(loc=\"upper left\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = []\n",
    "results = {\"Train Loss\": [], \"Train Accuracy\": [],\"Test Loss\": [],\"Test Accuracy\": [], \"Ratio\": [], \"Num. Params\": []}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking Convolutional Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1 Convolution Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:tf.keras.mixed_precision.experimental.LossScaleOptimizer is deprecated. Please use tf.keras.mixed_precision.LossScaleOptimizer instead. Note that the non-experimental LossScaleOptimizer does not take a DynamicLossScale but instead takes the dynamic configuration directly in the constructor. For example:\n",
      "  opt = tf.keras.mixed_precision.LossScaleOptimizer(opt)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "N_CONV  = 1\n",
    "CONV = 64\n",
    "KERNEL = 5\n",
    "N_DENSE = 1\n",
    "DENSE = 1024\n",
    "idx = 0\n",
    "checkpoint = ModelCheckpoint(f'model_{idx}.h5', save_best_only=True, monitor='val_accuracy', mode='max', verbose=0)\n",
    "lr_reducer = ReduceLROnPlateau(monitor='val_accuracy', patience=10, factor=0.5, min_lr=1e-6, mode='max', verbose=1)\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "gc.collect()\n",
    "\n",
    "model = build_model(n_conv = N_CONV, kernel_size= KERNEL, conv = CONV, n_dense = N_DENSE, dense = DENSE, opt = \"adam\")\n",
    "if not f'model_{idx}.h5' in os.listdir(\".\"):\n",
    "    history = model.fit(train_big,steps_per_epoch=train_big.samples // BATCH_SIZE, epochs=100, validation_data=test_big, validation_steps=test_big.samples // BATCH_SIZE, verbose = 0, callbacks=[checkpoint, lr_reducer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.6135  Train Loss: 1.0758\n",
      "Test Accuracy: 0.6555  Test Loss: 1.0011\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(f'model_{idx}.h5')\n",
    "title = \"{} Conv {} filters {} kernel size {} dense {} neurons\".format(N_CONV, CONV, KERNEL, N_DENSE, DENSE)\n",
    "experiment.append(title)\n",
    "if not f'model_{idx}.h5' in os.listdir(\".\"):\n",
    "    plot_loss_accuracy(history, title)\n",
    "(loss, acc) = model.evaluate(train_big, verbose = 0)\n",
    "results[\"Train Accuracy\"].append(acc)\n",
    "results[\"Train Loss\"].append(loss)\n",
    "results[\"Ratio\"].append(acc/(model.count_params()/100*1000))\n",
    "print(\"Train Accuracy: {:.4f}  Train Loss: {:.4f}\".format(acc,loss))\n",
    "(loss, acc) = model.evaluate(test_big, verbose = 0)\n",
    "results[\"Test Accuracy\"].append(acc)\n",
    "results[\"Test Loss\"].append(loss)\n",
    "print(\"Test Accuracy: {:.4f}  Test Loss: {:.4f}\".format(acc,loss))\n",
    "results[\"Num. Params\"].append(model.count_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 Convolution Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:tf.keras.mixed_precision.experimental.LossScaleOptimizer is deprecated. Please use tf.keras.mixed_precision.LossScaleOptimizer instead. Note that the non-experimental LossScaleOptimizer does not take a DynamicLossScale but instead takes the dynamic configuration directly in the constructor. For example:\n",
      "  opt = tf.keras.mixed_precision.LossScaleOptimizer(opt)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "N_CONV  = 2\n",
    "CONV = 64\n",
    "KERNEL = 5\n",
    "N_DENSE = 1\n",
    "DENSE = 1024\n",
    "idx = 1\n",
    "checkpoint = ModelCheckpoint(f'model_{idx}.h5', save_best_only=True, monitor='val_accuracy', mode='max', verbose=0)\n",
    "lr_reducer = ReduceLROnPlateau(monitor='val_accuracy', patience=10, factor=0.5, min_lr=1e-6, mode='max', verbose=1)\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "gc.collect()\n",
    "\n",
    "model = build_model(n_conv = N_CONV, kernel_size= KERNEL, conv = CONV, n_dense = N_DENSE, dense = DENSE, opt = \"adam\")\n",
    "if not f'model_{idx}.h5' in os.listdir(\".\"):\n",
    "    history = model.fit(train_big,steps_per_epoch=train_big.samples // BATCH_SIZE, epochs=100, validation_data=test_big, validation_steps=test_big.samples // BATCH_SIZE, verbose = 0, callbacks=[checkpoint, lr_reducer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.7363  Train Loss: 0.7412\n",
      "Test Accuracy: 0.7745  Test Loss: 0.6835\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(f'model_{idx}.h5')\n",
    "title = \"{} Conv {} filters {} kernel size {} dense {} neurons\".format(N_CONV, CONV, KERNEL, N_DENSE, DENSE)\n",
    "if not f'model_{idx}.h5' in os.listdir(\".\"):\n",
    "    plot_loss_accuracy(history, title)\n",
    "experiment.append(title)\n",
    "(loss, acc) = model.evaluate(train_big, verbose = 0)\n",
    "results[\"Train Accuracy\"].append(acc)\n",
    "results[\"Train Loss\"].append(loss)\n",
    "results[\"Ratio\"].append(acc/(model.count_params()/100*1000))\n",
    "print(\"Train Accuracy: {:.4f}  Train Loss: {:.4f}\".format(acc,loss))\n",
    "(loss, acc) = model.evaluate(test_big, verbose = 0)\n",
    "results[\"Test Accuracy\"].append(acc)\n",
    "results[\"Test Loss\"].append(loss)\n",
    "print(\"Test Accuracy: {:.4f}  Test Loss: {:.4f}\".format(acc,loss))\n",
    "results[\"Num. Params\"].append(model.count_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4 Convolution Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:tf.keras.mixed_precision.experimental.LossScaleOptimizer is deprecated. Please use tf.keras.mixed_precision.LossScaleOptimizer instead. Note that the non-experimental LossScaleOptimizer does not take a DynamicLossScale but instead takes the dynamic configuration directly in the constructor. For example:\n",
      "  opt = tf.keras.mixed_precision.LossScaleOptimizer(opt)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "N_CONV  = 4\n",
    "CONV = 64\n",
    "KERNEL = 5\n",
    "N_DENSE = 1\n",
    "DENSE = 1024\n",
    "idx = 2\n",
    "checkpoint = ModelCheckpoint(f'model_{idx}.h5', save_best_only=True, monitor='val_accuracy', mode='max', verbose=0)\n",
    "lr_reducer = ReduceLROnPlateau(monitor='val_accuracy', patience=10, factor=0.5, min_lr=1e-6, mode='max', verbose=1)\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "gc.collect()\n",
    "\n",
    "model = build_model(n_conv = N_CONV, kernel_size= KERNEL, conv = CONV, n_dense = N_DENSE, dense = DENSE, opt = \"adam\")\n",
    "if not f'model_{idx}.h5' in os.listdir(\".\"):\n",
    "    history = model.fit(train_big,steps_per_epoch=train_big.samples // BATCH_SIZE, epochs=100, validation_data=test_big, validation_steps=test_big.samples // BATCH_SIZE, verbose = 0, callbacks=[checkpoint, lr_reducer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.8570  Train Loss: 0.4197\n",
      "Test Accuracy: 0.8501  Test Loss: 0.4943\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(f'model_{idx}.h5')\n",
    "title = \"{} Conv {} filters {} kernel size {} dense {} neurons\".format(N_CONV, CONV, KERNEL, N_DENSE, DENSE)\n",
    "if not f'model_{idx}.h5' in os.listdir(\".\"):\n",
    "    plot_loss_accuracy(history, title)\n",
    "experiment.append(title)\n",
    "(loss, acc) = model.evaluate(train_big, verbose = 0)\n",
    "results[\"Train Accuracy\"].append(acc)\n",
    "results[\"Train Loss\"].append(loss)\n",
    "results[\"Ratio\"].append(acc/(model.count_params()/100*1000))\n",
    "print(\"Train Accuracy: {:.4f}  Train Loss: {:.4f}\".format(acc,loss))\n",
    "(loss, acc) = model.evaluate(test_big, verbose = 0)\n",
    "results[\"Test Accuracy\"].append(acc)\n",
    "results[\"Test Loss\"].append(loss)\n",
    "print(\"Test Accuracy: {:.4f}  Test Loss: {:.4f}\".format(acc,loss))\n",
    "results[\"Num. Params\"].append(model.count_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8 Convolution Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:tf.keras.mixed_precision.experimental.LossScaleOptimizer is deprecated. Please use tf.keras.mixed_precision.LossScaleOptimizer instead. Note that the non-experimental LossScaleOptimizer does not take a DynamicLossScale but instead takes the dynamic configuration directly in the constructor. For example:\n",
      "  opt = tf.keras.mixed_precision.LossScaleOptimizer(opt)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "N_CONV  = 8\n",
    "CONV = 64\n",
    "KERNEL = 5\n",
    "N_DENSE = 1\n",
    "DENSE = 1024\n",
    "idx = 3\n",
    "checkpoint = ModelCheckpoint(f'model_{idx}.h5', save_best_only=True, monitor='val_accuracy', mode='max', verbose=0)\n",
    "lr_reducer = ReduceLROnPlateau(monitor='val_accuracy', patience=10, factor=0.5, min_lr=1e-6, mode='max', verbose=1)\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "gc.collect()\n",
    "\n",
    "model = build_model(n_conv = N_CONV, kernel_size= KERNEL, conv = CONV, n_dense = N_DENSE, dense = DENSE, opt = \"adam\")\n",
    "if not f'model_{idx}.h5' in os.listdir(\".\"):\n",
    "    history = model.fit(train_big,steps_per_epoch=train_big.samples // BATCH_SIZE, epochs=100, validation_data=test_big, validation_steps=test_big.samples // BATCH_SIZE, verbose = 0, callbacks=[checkpoint, lr_reducer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.8671  Train Loss: 0.3864\n",
      "Test Accuracy: 0.8426  Test Loss: 0.4908\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(f'model_{idx}.h5')\n",
    "title = \"{} Conv {} filters {} kernel size {} dense {} neurons\".format(N_CONV, CONV, KERNEL, N_DENSE, DENSE)\n",
    "if not f'model_{idx}.h5' in os.listdir(\".\"):\n",
    "    plot_loss_accuracy(history, title)\n",
    "experiment.append(title)\n",
    "(loss, acc) = model.evaluate(train_big, verbose = 0)\n",
    "results[\"Train Accuracy\"].append(acc)\n",
    "results[\"Train Loss\"].append(loss)\n",
    "results[\"Ratio\"].append(acc/(model.count_params()/100*1000))\n",
    "print(\"Train Accuracy: {:.4f}  Train Loss: {:.4f}\".format(acc,loss))\n",
    "(loss, acc) = model.evaluate(test_big, verbose = 0)\n",
    "results[\"Test Accuracy\"].append(acc)\n",
    "results[\"Test Loss\"].append(loss)\n",
    "print(\"Test Accuracy: {:.4f}  Test Loss: {:.4f}\".format(acc,loss))\n",
    "results[\"Num. Params\"].append(model.count_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking Dense Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 Dense Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:tf.keras.mixed_precision.experimental.LossScaleOptimizer is deprecated. Please use tf.keras.mixed_precision.LossScaleOptimizer instead. Note that the non-experimental LossScaleOptimizer does not take a DynamicLossScale but instead takes the dynamic configuration directly in the constructor. For example:\n",
      "  opt = tf.keras.mixed_precision.LossScaleOptimizer(opt)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "N_CONV  = 4\n",
    "CONV = 64\n",
    "KERNEL = 5\n",
    "N_DENSE = 2\n",
    "DENSE = 1024\n",
    "idx = 4\n",
    "checkpoint = ModelCheckpoint(f'model_{idx}.h5', save_best_only=True, monitor='val_accuracy', mode='max', verbose=0)\n",
    "lr_reducer = ReduceLROnPlateau(monitor='val_accuracy', patience=10, factor=0.5, min_lr=1e-6, mode='max', verbose=1)\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "gc.collect()\n",
    "\n",
    "model = build_model(n_conv = N_CONV, kernel_size= KERNEL, conv = CONV, n_dense = N_DENSE, dense = DENSE, opt = \"adam\")\n",
    "if not f'model_{idx}.h5' in os.listdir(\".\"):\n",
    "    history = model.fit(train_big,steps_per_epoch=train_big.samples // BATCH_SIZE, epochs=100, validation_data=test_big, validation_steps=test_big.samples // BATCH_SIZE, verbose = 0, callbacks=[checkpoint, lr_reducer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.8974  Train Loss: 0.3033\n",
      "Test Accuracy: 0.8538  Test Loss: 0.4606\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(f'model_{idx}.h5')\n",
    "title = \"{} Conv {} filters {} kernel size {} dense {} neurons\".format(N_CONV, CONV, KERNEL, N_DENSE, DENSE)\n",
    "if not f'model_{idx}.h5' in os.listdir(\".\"):\n",
    "    plot_loss_accuracy(history, title)\n",
    "experiment.append(title)\n",
    "(loss, acc) = model.evaluate(train_big, verbose = 0)\n",
    "results[\"Train Accuracy\"].append(acc)\n",
    "results[\"Train Loss\"].append(loss)\n",
    "results[\"Ratio\"].append(acc/(model.count_params()/100*1000))\n",
    "print(\"Train Accuracy: {:.4f}  Train Loss: {:.4f}\".format(acc,loss))\n",
    "(loss, acc) = model.evaluate(test_big, verbose = 0)\n",
    "results[\"Test Accuracy\"].append(acc)\n",
    "results[\"Test Loss\"].append(loss)\n",
    "print(\"Test Accuracy: {:.4f}  Test Loss: {:.4f}\".format(acc,loss))\n",
    "results[\"Num. Params\"].append(model.count_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4 Dense Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:tf.keras.mixed_precision.experimental.LossScaleOptimizer is deprecated. Please use tf.keras.mixed_precision.LossScaleOptimizer instead. Note that the non-experimental LossScaleOptimizer does not take a DynamicLossScale but instead takes the dynamic configuration directly in the constructor. For example:\n",
      "  opt = tf.keras.mixed_precision.LossScaleOptimizer(opt)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "N_CONV  = 4\n",
    "CONV = 64\n",
    "KERNEL = 5\n",
    "N_DENSE = 4\n",
    "DENSE = 1024\n",
    "idx = 5\n",
    "checkpoint = ModelCheckpoint(f'model_{idx}.h5', save_best_only=True, monitor='val_accuracy', mode='max', verbose=0)\n",
    "lr_reducer = ReduceLROnPlateau(monitor='val_accuracy', patience=10, factor=0.5, min_lr=1e-6, mode='max', verbose=1)\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "gc.collect()\n",
    "\n",
    "model = build_model(n_conv = N_CONV, kernel_size= KERNEL, conv = CONV, n_dense = N_DENSE, dense = DENSE, opt = \"adam\")\n",
    "if not f'model_{idx}.h5' in os.listdir(\".\"):\n",
    "    history = model.fit(train_big,steps_per_epoch=train_big.samples // BATCH_SIZE, epochs=100, validation_data=test_big, validation_steps=test_big.samples // BATCH_SIZE, verbose = 0, callbacks=[checkpoint, lr_reducer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.8979  Train Loss: 0.3059\n",
      "Test Accuracy: 0.8686  Test Loss: 0.4426\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(f'model_{idx}.h5')\n",
    "title = \"{} Conv {} filters {} kernel size {} dense {} neurons\".format(N_CONV, CONV, KERNEL, N_DENSE, DENSE)\n",
    "if not f'model_{idx}.h5' in os.listdir(\".\"):\n",
    "    plot_loss_accuracy(history, title)\n",
    "experiment.append(title)\n",
    "(loss, acc) = model.evaluate(train_big, verbose = 0)\n",
    "results[\"Train Accuracy\"].append(acc)\n",
    "results[\"Train Loss\"].append(loss)\n",
    "results[\"Ratio\"].append(acc/(model.count_params()/100*1000))\n",
    "print(\"Train Accuracy: {:.4f}  Train Loss: {:.4f}\".format(acc,loss))\n",
    "(loss, acc) = model.evaluate(test_big, verbose = 0)\n",
    "results[\"Test Accuracy\"].append(acc)\n",
    "results[\"Test Loss\"].append(loss)\n",
    "print(\"Test Accuracy: {:.4f}  Test Loss: {:.4f}\".format(acc,loss))\n",
    "results[\"Num. Params\"].append(model.count_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking Number of Filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 32 Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:tf.keras.mixed_precision.experimental.LossScaleOptimizer is deprecated. Please use tf.keras.mixed_precision.LossScaleOptimizer instead. Note that the non-experimental LossScaleOptimizer does not take a DynamicLossScale but instead takes the dynamic configuration directly in the constructor. For example:\n",
      "  opt = tf.keras.mixed_precision.LossScaleOptimizer(opt)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "N_CONV  = 4\n",
    "CONV = 32\n",
    "KERNEL = 5\n",
    "N_DENSE = 2\n",
    "DENSE = 1024\n",
    "idx = 6\n",
    "checkpoint = ModelCheckpoint(f'model_{idx}.h5', save_best_only=True, monitor='val_accuracy', mode='max', verbose=0)\n",
    "lr_reducer = ReduceLROnPlateau(monitor='val_accuracy', patience=10, factor=0.5, min_lr=1e-6, mode='max', verbose=1)\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "gc.collect()\n",
    "\n",
    "model = build_model(n_conv = N_CONV, kernel_size= KERNEL, conv = CONV, n_dense = N_DENSE, dense = DENSE, opt = \"adam\")\n",
    "if not f'model_{idx}.h5' in os.listdir(\".\"):\n",
    "    history = model.fit(train_big,steps_per_epoch=train_big.samples // BATCH_SIZE, epochs=100, validation_data=test_big, validation_steps=test_big.samples // BATCH_SIZE, verbose = 0, callbacks=[checkpoint, lr_reducer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.8623  Train Loss: 0.4084\n",
      "Test Accuracy: 0.8439  Test Loss: 0.5130\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(f'model_{idx}.h5')\n",
    "title = \"{} Conv {} filters {} kernel size {} dense {} neurons\".format(N_CONV, CONV, KERNEL, N_DENSE, DENSE)\n",
    "if not f'model_{idx}.h5' in os.listdir(\".\"):\n",
    "    plot_loss_accuracy(history, title)\n",
    "experiment.append(title)\n",
    "(loss, acc) = model.evaluate(train_big, verbose = 0)\n",
    "results[\"Train Accuracy\"].append(acc)\n",
    "results[\"Train Loss\"].append(loss)\n",
    "results[\"Ratio\"].append(acc/(model.count_params()/100*1000))\n",
    "print(\"Train Accuracy: {:.4f}  Train Loss: {:.4f}\".format(acc,loss))\n",
    "(loss, acc) = model.evaluate(test_big, verbose = 0)\n",
    "results[\"Test Accuracy\"].append(acc)\n",
    "results[\"Test Loss\"].append(loss)\n",
    "print(\"Test Accuracy: {:.4f}  Test Loss: {:.4f}\".format(acc,loss))\n",
    "results[\"Num. Params\"].append(model.count_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 128 Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:tf.keras.mixed_precision.experimental.LossScaleOptimizer is deprecated. Please use tf.keras.mixed_precision.LossScaleOptimizer instead. Note that the non-experimental LossScaleOptimizer does not take a DynamicLossScale but instead takes the dynamic configuration directly in the constructor. For example:\n",
      "  opt = tf.keras.mixed_precision.LossScaleOptimizer(opt)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "N_CONV  = 4\n",
    "CONV = 128\n",
    "KERNEL = 5\n",
    "N_DENSE = 2\n",
    "DENSE = 1024\n",
    "idx = 7\n",
    "checkpoint = ModelCheckpoint(f'model_{idx}.h5', save_best_only=True, monitor='val_accuracy', mode='max', verbose=0)\n",
    "lr_reducer = ReduceLROnPlateau(monitor='val_accuracy', patience=10, factor=0.5, min_lr=1e-6, mode='max', verbose=1)\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "gc.collect()\n",
    "\n",
    "model = build_model(n_conv = N_CONV, kernel_size= KERNEL, conv = CONV, n_dense = N_DENSE, dense = DENSE, opt = \"adam\")\n",
    "if not f'model_{idx}.h5' in os.listdir(\".\"):\n",
    "    history = model.fit(train_big,steps_per_epoch=train_big.samples // BATCH_SIZE, epochs=100, validation_data=test_big, validation_steps=test_big.samples // BATCH_SIZE, verbose = 0, callbacks=[checkpoint, lr_reducer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.8830  Train Loss: 0.3153\n",
      "Test Accuracy: 0.8625  Test Loss: 0.4074\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(f'model_{idx}.h5')\n",
    "title = \"{} Conv {} filters {} kernel size {} dense {} neurons\".format(N_CONV, CONV, KERNEL, N_DENSE, DENSE)\n",
    "if not f'model_{idx}.h5' in os.listdir(\".\"):\n",
    "    plot_loss_accuracy(history, title)\n",
    "experiment.append(title)\n",
    "(loss, acc) = model.evaluate(train_big, verbose = 0)\n",
    "results[\"Train Accuracy\"].append(acc)\n",
    "results[\"Train Loss\"].append(loss)\n",
    "results[\"Ratio\"].append(acc/(model.count_params()/100*1000))\n",
    "print(\"Train Accuracy: {:.4f}  Train Loss: {:.4f}\".format(acc,loss))\n",
    "(loss, acc) = model.evaluate(test_big, verbose = 0)\n",
    "results[\"Test Accuracy\"].append(acc)\n",
    "results[\"Test Loss\"].append(loss)\n",
    "print(\"Test Accuracy: {:.4f}  Test Loss: {:.4f}\".format(acc,loss))\n",
    "results[\"Num. Params\"].append(model.count_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 256 Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:tf.keras.mixed_precision.experimental.LossScaleOptimizer is deprecated. Please use tf.keras.mixed_precision.LossScaleOptimizer instead. Note that the non-experimental LossScaleOptimizer does not take a DynamicLossScale but instead takes the dynamic configuration directly in the constructor. For example:\n",
      "  opt = tf.keras.mixed_precision.LossScaleOptimizer(opt)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "N_CONV  = 4\n",
    "CONV = 256\n",
    "KERNEL = 5\n",
    "N_DENSE = 2\n",
    "DENSE = 1024\n",
    "idx = 8\n",
    "checkpoint = ModelCheckpoint(f'model_{idx}.h5', save_best_only=True, monitor='val_accuracy', mode='max', verbose=0)\n",
    "lr_reducer = ReduceLROnPlateau(monitor='val_accuracy', patience=10, factor=0.5, min_lr=1e-6, mode='max', verbose=1)\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "gc.collect()\n",
    "\n",
    "model = build_model(n_conv = N_CONV, kernel_size= KERNEL, conv = CONV, n_dense = N_DENSE, dense = DENSE, opt = \"adam\")\n",
    "if not f'model_{idx}.h5' in os.listdir(\".\"):\n",
    "    history = model.fit(train_big,steps_per_epoch=train_big.samples // BATCH_SIZE, epochs=100, validation_data=test_big, validation_steps=test_big.samples // BATCH_SIZE, verbose = 0, callbacks=[checkpoint, lr_reducer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.8703  Train Loss: 0.3822\n",
      "Test Accuracy: 0.8463  Test Loss: 0.4777\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(f'model_{idx}.h5')\n",
    "title = \"{} Conv {} filters {} kernel size {} dense {} neurons\".format(N_CONV, CONV, KERNEL, N_DENSE, DENSE)\n",
    "if not f'model_{idx}.h5' in os.listdir(\".\"):\n",
    "    plot_loss_accuracy(history, title)\n",
    "experiment.append(title)\n",
    "(loss, acc) = model.evaluate(train_big, verbose = 0)\n",
    "results[\"Train Accuracy\"].append(acc)\n",
    "results[\"Train Loss\"].append(loss)\n",
    "results[\"Ratio\"].append(acc/(model.count_params()/100*1000))\n",
    "print(\"Train Accuracy: {:.4f}  Train Loss: {:.4f}\".format(acc,loss))\n",
    "(loss, acc) = model.evaluate(test_big, verbose = 0)\n",
    "results[\"Test Accuracy\"].append(acc)\n",
    "results[\"Test Loss\"].append(loss)\n",
    "print(\"Test Accuracy: {:.4f}  Test Loss: {:.4f}\".format(acc,loss))\n",
    "results[\"Num. Params\"].append(model.count_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding MaxPooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:tf.keras.mixed_precision.experimental.LossScaleOptimizer is deprecated. Please use tf.keras.mixed_precision.LossScaleOptimizer instead. Note that the non-experimental LossScaleOptimizer does not take a DynamicLossScale but instead takes the dynamic configuration directly in the constructor. For example:\n",
      "  opt = tf.keras.mixed_precision.LossScaleOptimizer(opt)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "N_CONV  = 4\n",
    "CONV = 256\n",
    "KERNEL = 5\n",
    "N_DENSE = 2\n",
    "DENSE = 1024\n",
    "MAX_POOLING = True\n",
    "idx = 9\n",
    "checkpoint = ModelCheckpoint(f'model_{idx}.h5', save_best_only=True, monitor='val_accuracy', mode='max', verbose=0)\n",
    "lr_reducer = ReduceLROnPlateau(monitor='val_accuracy', patience=10, factor=0.5, min_lr=1e-6, mode='max', verbose=1)\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "gc.collect()\n",
    "\n",
    "model = build_model(n_conv = N_CONV, kernel_size= KERNEL, conv = CONV, n_dense = N_DENSE, dense = DENSE, max_pool = MAX_POOLING, opt = \"adam\")\n",
    "if not f'model_{idx}.h5' in os.listdir(\".\"):\n",
    "    history = model.fit(train_big,steps_per_epoch=train_big.samples // BATCH_SIZE, epochs=100, validation_data=test_big, validation_steps=test_big.samples // BATCH_SIZE, verbose = 0, callbacks=[checkpoint, lr_reducer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.9203  Train Loss: 0.2234\n",
      "Test Accuracy: 0.8637  Test Loss: 0.5073\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(f'model_{idx}.h5')\n",
    "title = \"{} Conv {} filters {} kernel size {} dense {} neurons with MaxPooling\".format(N_CONV, CONV, KERNEL, N_DENSE, DENSE)\n",
    "if not f'model_{idx}.h5' in os.listdir(\".\"):\n",
    "    plot_loss_accuracy(history, title)\n",
    "experiment.append(title)\n",
    "(loss, acc) = model.evaluate(train_big, verbose = 0)\n",
    "results[\"Train Accuracy\"].append(acc)\n",
    "results[\"Train Loss\"].append(loss)\n",
    "results[\"Ratio\"].append(acc/(model.count_params()/100*1000))\n",
    "print(\"Train Accuracy: {:.4f}  Train Loss: {:.4f}\".format(acc,loss))\n",
    "(loss, acc) = model.evaluate(test_big, verbose = 0)\n",
    "results[\"Test Accuracy\"].append(acc)\n",
    "results[\"Test Loss\"].append(loss)\n",
    "print(\"Test Accuracy: {:.4f}  Test Loss: {:.4f}\".format(acc,loss))\n",
    "results[\"Num. Params\"].append(model.count_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:tf.keras.mixed_precision.experimental.LossScaleOptimizer is deprecated. Please use tf.keras.mixed_precision.LossScaleOptimizer instead. Note that the non-experimental LossScaleOptimizer does not take a DynamicLossScale but instead takes the dynamic configuration directly in the constructor. For example:\n",
      "  opt = tf.keras.mixed_precision.LossScaleOptimizer(opt)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "N_CONV  = 4\n",
    "CONV = 256\n",
    "KERNEL = 5\n",
    "N_DENSE = 2\n",
    "DENSE = 1024\n",
    "DROPOUT = True\n",
    "idx=10\n",
    "checkpoint = ModelCheckpoint(f'model_{idx}.h5', save_best_only=True, monitor='val_accuracy', mode='max', verbose=0)\n",
    "lr_reducer = ReduceLROnPlateau(monitor='val_accuracy', patience=10, factor=0.5, min_lr=1e-6, mode='max', verbose=1)\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "gc.collect()\n",
    "\n",
    "model = build_model(n_conv = N_CONV, kernel_size= KERNEL, conv = CONV, n_dense = N_DENSE, dense = DENSE, dropout = DROPOUT, opt = \"adam\")\n",
    "if not f'model_{idx}.h5' in os.listdir(\".\"):\n",
    "    history = model.fit(train_big,steps_per_epoch=train_big.samples // BATCH_SIZE, epochs=100, validation_data=test_big, validation_steps=test_big.samples // BATCH_SIZE, verbose = 0, callbacks=[checkpoint, lr_reducer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.8862  Train Loss: 0.3031\n",
      "Test Accuracy: 0.8612  Test Loss: 0.4374\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(f'model_{idx}.h5')\n",
    "title = \"{} Conv {} filters {} kernel size {} dense {} neurons with 0.2 Dropout on FC\".format(N_CONV, CONV, KERNEL, N_DENSE, DENSE)\n",
    "if not f'model_{idx}.h5' in os.listdir(\".\"):\n",
    "    plot_loss_accuracy(history, title)\n",
    "experiment.append(title)\n",
    "(loss, acc) = model.evaluate(train_big, verbose = 0)\n",
    "results[\"Train Accuracy\"].append(acc)\n",
    "results[\"Train Loss\"].append(loss)\n",
    "results[\"Ratio\"].append(acc/(model.count_params()/100*1000))\n",
    "print(\"Train Accuracy: {:.4f}  Train Loss: {:.4f}\".format(acc,loss))\n",
    "(loss, acc) = model.evaluate(test_big, verbose = 0)\n",
    "results[\"Test Accuracy\"].append(acc)\n",
    "results[\"Test Loss\"].append(loss)\n",
    "print(\"Test Accuracy: {:.4f}  Test Loss: {:.4f}\".format(acc,loss))\n",
    "results[\"Num. Params\"].append(model.count_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:tf.keras.mixed_precision.experimental.LossScaleOptimizer is deprecated. Please use tf.keras.mixed_precision.LossScaleOptimizer instead. Note that the non-experimental LossScaleOptimizer does not take a DynamicLossScale but instead takes the dynamic configuration directly in the constructor. For example:\n",
      "  opt = tf.keras.mixed_precision.LossScaleOptimizer(opt)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "N_CONV  = 4\n",
    "CONV = 256\n",
    "KERNEL = 5\n",
    "N_DENSE = 2\n",
    "DENSE = 1024\n",
    "BATCH_NORM = True\n",
    "idx = 11\n",
    "checkpoint = ModelCheckpoint(f'model_{idx}.h5', save_best_only=True, monitor='val_accuracy', mode='max', verbose=0)\n",
    "lr_reducer = ReduceLROnPlateau(monitor='val_accuracy', patience=10, factor=0.5, min_lr=1e-6, mode='max', verbose=1)\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "gc.collect()\n",
    "\n",
    "model = build_model(n_conv = N_CONV, kernel_size= KERNEL, conv = CONV, n_dense = N_DENSE, dense = DENSE, batch_norm = BATCH_NORM, opt = \"adam\")\n",
    "if not f'model_{idx}.h5' in os.listdir(\".\"):\n",
    "    history = model.fit(train_big,steps_per_epoch=train_big.samples // BATCH_SIZE, epochs=100, validation_data=test_big, validation_steps=test_big.samples // BATCH_SIZE, verbose = 0, callbacks=[checkpoint, lr_reducer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.9872  Train Loss: 0.0613\n",
      "Test Accuracy: 0.8786  Test Loss: 0.4408\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(f'model_{idx}.h5')\n",
    "title = \"{} Conv {} filters {} kernel size {} dense {} neurons with BatchNorm\".format(N_CONV, CONV, KERNEL, N_DENSE, DENSE)\n",
    "if not f'model_{idx}.h5' in os.listdir(\".\"):\n",
    "    plot_loss_accuracy(history, title)\n",
    "experiment.append(title)\n",
    "(loss, acc) = model.evaluate(train_big, verbose = 0)\n",
    "results[\"Train Accuracy\"].append(acc)\n",
    "results[\"Train Loss\"].append(loss)\n",
    "results[\"Ratio\"].append(acc/(model.count_params()/100*1000))\n",
    "print(\"Train Accuracy: {:.4f}  Train Loss: {:.4f}\".format(acc,loss))\n",
    "(loss, acc) = model.evaluate(test_big, verbose = 0)\n",
    "results[\"Test Accuracy\"].append(acc)\n",
    "results[\"Test Loss\"].append(loss)\n",
    "print(\"Test Accuracy: {:.4f}  Test Loss: {:.4f}\".format(acc,loss))\n",
    "results[\"Num. Params\"].append(model.count_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding MaxPooling and Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:tf.keras.mixed_precision.experimental.LossScaleOptimizer is deprecated. Please use tf.keras.mixed_precision.LossScaleOptimizer instead. Note that the non-experimental LossScaleOptimizer does not take a DynamicLossScale but instead takes the dynamic configuration directly in the constructor. For example:\n",
      "  opt = tf.keras.mixed_precision.LossScaleOptimizer(opt)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "N_CONV  = 4\n",
    "CONV = 256\n",
    "KERNEL = 5\n",
    "N_DENSE = 2\n",
    "DENSE = 1024\n",
    "MAX_POOLING = True\n",
    "DROPOUT = True\n",
    "idx = 12\n",
    "checkpoint = ModelCheckpoint(f'model_{idx}.h5', save_best_only=True, monitor='val_accuracy', mode='max', verbose=0)\n",
    "lr_reducer = ReduceLROnPlateau(monitor='val_accuracy', patience=10, factor=0.5, min_lr=1e-6, mode='max', verbose=1)\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "gc.collect()\n",
    "\n",
    "model = build_model(n_conv = N_CONV, kernel_size= KERNEL, conv = CONV, n_dense = N_DENSE, dense = DENSE, max_pool = MAX_POOLING, dropout = DROPOUT, opt = \"adam\")\n",
    "if not f'model_{idx}.h5' in os.listdir(\".\"):\n",
    "    history = model.fit(train_big,steps_per_epoch=train_big.samples // BATCH_SIZE, epochs=100, validation_data=test_big, validation_steps=test_big.samples // BATCH_SIZE, verbose = 0, callbacks=[checkpoint, lr_reducer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.9266  Train Loss: 0.1964\n",
      "Test Accuracy: 0.8674  Test Loss: 0.4081\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(f'model_{idx}.h5')\n",
    "title = \"Conv {} filters {} kernel size {} dense {} neurons with MaxPooling and Dropout\".format(N_CONV, CONV, KERNEL, N_DENSE, DENSE)\n",
    "if not f'model_{idx}.h5' in os.listdir(\".\"):\n",
    "    plot_loss_accuracy(history, title)\n",
    "experiment.append(title)\n",
    "(loss, acc) = model.evaluate(train_big, verbose = 0)\n",
    "results[\"Train Accuracy\"].append(acc)\n",
    "results[\"Train Loss\"].append(loss)\n",
    "results[\"Ratio\"].append(acc/(model.count_params()/100*1000))\n",
    "print(\"Train Accuracy: {:.4f}  Train Loss: {:.4f}\".format(acc,loss))\n",
    "(loss, acc) = model.evaluate(test_big, verbose = 0)\n",
    "results[\"Test Accuracy\"].append(acc)\n",
    "results[\"Test Loss\"].append(loss)\n",
    "print(\"Test Accuracy: {:.4f}  Test Loss: {:.4f}\".format(acc,loss))\n",
    "results[\"Num. Params\"].append(model.count_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding MaxPooling and Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:tf.keras.mixed_precision.experimental.LossScaleOptimizer is deprecated. Please use tf.keras.mixed_precision.LossScaleOptimizer instead. Note that the non-experimental LossScaleOptimizer does not take a DynamicLossScale but instead takes the dynamic configuration directly in the constructor. For example:\n",
      "  opt = tf.keras.mixed_precision.LossScaleOptimizer(opt)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "N_CONV  = 4\n",
    "CONV = 256\n",
    "KERNEL = 5\n",
    "N_DENSE = 2\n",
    "DENSE = 1024\n",
    "MAX_POOLING = True\n",
    "BATCH_NORM = True\n",
    "idx = 13\n",
    "checkpoint = ModelCheckpoint(f'model_{idx}.h5', save_best_only=True, monitor='val_accuracy', mode='max', verbose=0)\n",
    "lr_reducer = ReduceLROnPlateau(monitor='val_accuracy', patience=10, factor=0.5, min_lr=1e-6, mode='max', verbose=1)\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "gc.collect()\n",
    "\n",
    "model = build_model(n_conv = N_CONV, kernel_size= KERNEL, conv = CONV, n_dense = N_DENSE, dense = DENSE, max_pool = MAX_POOLING, batch_norm = BATCH_NORM, opt = \"adam\")\n",
    "if not f'model_{idx}.h5' in os.listdir(\".\"):\n",
    "    history = model.fit(train_big,steps_per_epoch=train_big.samples // BATCH_SIZE, epochs=100, validation_data=test_big, validation_steps=test_big.samples // BATCH_SIZE, verbose = 0, callbacks=[checkpoint, lr_reducer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.9702  Train Loss: 0.1024\n",
      "Test Accuracy: 0.8872  Test Loss: 0.3982\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(f'model_{idx}.h5')\n",
    "title = \"{} Conv {} filters {} kernel size {} dense {} neurons with MaxPooling and BatchNorm\".format(N_CONV, CONV, KERNEL, N_DENSE, DENSE)\n",
    "if not f'model_{idx}.h5' in os.listdir(\".\"):\n",
    "    plot_loss_accuracy(history, title)\n",
    "experiment.append(title)\n",
    "(loss, acc) = model.evaluate(train_big, verbose = 0)\n",
    "results[\"Train Accuracy\"].append(acc)\n",
    "results[\"Train Loss\"].append(loss)\n",
    "results[\"Ratio\"].append(acc/(model.count_params()/100*1000))\n",
    "print(\"Train Accuracy: {:.4f}  Train Loss: {:.4f}\".format(acc,loss))\n",
    "(loss, acc) = model.evaluate(test_big, verbose = 0)\n",
    "results[\"Test Accuracy\"].append(acc)\n",
    "results[\"Test Loss\"].append(loss)\n",
    "print(\"Test Accuracy: {:.4f}  Test Loss: {:.4f}\".format(acc,loss))\n",
    "results[\"Num. Params\"].append(model.count_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding Batch Normalization and Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:tf.keras.mixed_precision.experimental.LossScaleOptimizer is deprecated. Please use tf.keras.mixed_precision.LossScaleOptimizer instead. Note that the non-experimental LossScaleOptimizer does not take a DynamicLossScale but instead takes the dynamic configuration directly in the constructor. For example:\n",
      "  opt = tf.keras.mixed_precision.LossScaleOptimizer(opt)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "N_CONV  = 4\n",
    "CONV = 256\n",
    "KERNEL = 5\n",
    "N_DENSE = 2\n",
    "DENSE = 1024\n",
    "DROPOUT = True\n",
    "BATCH_NORM = True\n",
    "idx = 14\n",
    "checkpoint = ModelCheckpoint(f'model_{idx}.h5', save_best_only=True, monitor='val_accuracy', mode='max', verbose=0)\n",
    "lr_reducer = ReduceLROnPlateau(monitor='val_accuracy', patience=10, factor=0.5, min_lr=1e-6, mode='max', verbose=1)\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "gc.collect()\n",
    "\n",
    "model = build_model(n_conv = N_CONV, kernel_size= KERNEL, conv = CONV, n_dense = N_DENSE, dense = DENSE, max_pool = MAX_POOLING, dropout = DROPOUT, opt = \"adam\")\n",
    "if not f'model_{idx}.h5' in os.listdir(\".\"):\n",
    "    history = model.fit(train_big,steps_per_epoch=train_big.samples // BATCH_SIZE, epochs=100, validation_data=test_big, validation_steps=test_big.samples // BATCH_SIZE, verbose = 0, callbacks=[checkpoint, lr_reducer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.9224  Train Loss: 0.2266\n",
      "Test Accuracy: 0.8649  Test Loss: 0.4379\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(f'model_{idx}.h5')\n",
    "title = \"{} Conv {} filters {} kernel size {} dense {} neurons with MaxPooling and Dropout\".format(N_CONV, CONV, KERNEL, N_DENSE, DENSE)\n",
    "if not f'model_{idx}.h5' in os.listdir(\".\"):\n",
    "    plot_loss_accuracy(history, title)\n",
    "experiment.append(title)\n",
    "(loss, acc) = model.evaluate(train_big, verbose = 0)\n",
    "results[\"Train Accuracy\"].append(acc)\n",
    "results[\"Train Loss\"].append(loss)\n",
    "results[\"Ratio\"].append(acc/(model.count_params()/100*1000))\n",
    "print(\"Train Accuracy: {:.4f}  Train Loss: {:.4f}\".format(acc,loss))\n",
    "(loss, acc) = model.evaluate(test_big, verbose = 0)\n",
    "results[\"Test Accuracy\"].append(acc)\n",
    "results[\"Test Loss\"].append(loss)\n",
    "print(\"Test Accuracy: {:.4f}  Test Loss: {:.4f}\".format(acc,loss))\n",
    "results[\"Num. Params\"].append(model.count_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding Batch Normalization, MaxPooling and Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:tf.keras.mixed_precision.experimental.LossScaleOptimizer is deprecated. Please use tf.keras.mixed_precision.LossScaleOptimizer instead. Note that the non-experimental LossScaleOptimizer does not take a DynamicLossScale but instead takes the dynamic configuration directly in the constructor. For example:\n",
      "  opt = tf.keras.mixed_precision.LossScaleOptimizer(opt)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "N_CONV  = 4\n",
    "CONV = 256\n",
    "KERNEL = 5\n",
    "N_DENSE = 2\n",
    "DENSE = 1024\n",
    "DROPOUT = True\n",
    "BATCH_NORM = True\n",
    "MAX_POOLING = True\n",
    "idx = 15\n",
    "checkpoint = ModelCheckpoint(f'model_{idx}.h5', save_best_only=True, monitor='val_accuracy', mode='max', verbose=0)\n",
    "lr_reducer = ReduceLROnPlateau(monitor='val_accuracy', patience=10, factor=0.5, min_lr=1e-6, mode='max', verbose=1)\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "gc.collect()\n",
    "\n",
    "model = build_model(n_conv = N_CONV, kernel_size= KERNEL, conv = CONV, n_dense = N_DENSE, dense = DENSE, max_pool = MAX_POOLING, dropout = DROPOUT, batch_norm = BATCH_NORM, opt = \"adam\")\n",
    "if not f'model_{idx}.h5' in os.listdir(\".\"):\n",
    "    history = model.fit(train_big,steps_per_epoch=train_big.samples // BATCH_SIZE, epochs=100, validation_data=test_big, validation_steps=test_big.samples // BATCH_SIZE,  verbose = 0, callbacks=[checkpoint, lr_reducer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.9601  Train Loss: 0.1276\n",
      "Test Accuracy: 0.8897  Test Loss: 0.3572\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(f'model_{idx}.h5')\n",
    "title = \"{} Conv {} filters {} kernel size {} dense {} neurons with BatchNorm, MaxPooling and Dropout\".format(N_CONV, CONV, KERNEL, N_DENSE, DENSE)\n",
    "if not f'model_{idx}.h5' in os.listdir(\".\"):\n",
    "    plot_loss_accuracy(history, title)\n",
    "experiment.append(title)\n",
    "(loss, acc) = model.evaluate(train_big, verbose = 0)\n",
    "results[\"Train Accuracy\"].append(acc)\n",
    "results[\"Train Loss\"].append(loss)\n",
    "results[\"Ratio\"].append(acc/(model.count_params()/100*1000))\n",
    "print(\"Train Accuracy: {:.4f}  Train Loss: {:.4f}\".format(acc,loss))\n",
    "(loss, acc) = model.evaluate(test_big, verbose = 0)\n",
    "results[\"Test Accuracy\"].append(acc)\n",
    "results[\"Test Loss\"].append(loss)\n",
    "print(\"Test Accuracy: {:.4f}  Test Loss: {:.4f}\".format(acc,loss))\n",
    "results[\"Num. Params\"].append(model.count_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking Kernel Size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3 Kernel Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:tf.keras.mixed_precision.experimental.LossScaleOptimizer is deprecated. Please use tf.keras.mixed_precision.LossScaleOptimizer instead. Note that the non-experimental LossScaleOptimizer does not take a DynamicLossScale but instead takes the dynamic configuration directly in the constructor. For example:\n",
      "  opt = tf.keras.mixed_precision.LossScaleOptimizer(opt)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "N_CONV  = 4\n",
    "CONV = 256\n",
    "KERNEL = 3\n",
    "N_DENSE = 2\n",
    "DENSE = 1024\n",
    "DROPOUT = True\n",
    "BATCH_NORM = False\n",
    "MAX_POOLING = False\n",
    "idx = 16\n",
    "checkpoint = ModelCheckpoint(f'model_{idx}.h5', save_best_only=True, monitor='val_accuracy', mode='max', verbose=0)\n",
    "lr_reducer = ReduceLROnPlateau(monitor='val_accuracy', patience=10, factor=0.5, min_lr=1e-6, mode='max', verbose=1)\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "gc.collect()\n",
    "\n",
    "model = build_model(n_conv = N_CONV, kernel_size= KERNEL, conv = CONV, n_dense = N_DENSE, dense = DENSE, max_pool = MAX_POOLING, dropout = DROPOUT, batch_norm = BATCH_NORM, opt = \"adam\")\n",
    "if not f'model_{idx}.h5' in os.listdir(\".\"):\n",
    "    history = model.fit(train_big,steps_per_epoch=train_big.samples // BATCH_SIZE, epochs=100, validation_data=test_big, validation_steps=test_big.samples // BATCH_SIZE,  verbose = 0, callbacks=[checkpoint, lr_reducer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.8995  Train Loss: 0.3013\n",
      "Test Accuracy: 0.8439  Test Loss: 0.5045\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(f'model_{idx}.h5')\n",
    "title = \"{} Conv {} filters {} kernel size {} dense {} neurons with 0.2 Dropout on FC\".format(N_CONV, CONV, KERNEL, N_DENSE, DENSE)\n",
    "if not f'model_{idx}.h5' in os.listdir(\".\"):\n",
    "    plot_loss_accuracy(history, title)\n",
    "experiment.append(title)\n",
    "(loss, acc) = model.evaluate(train_big, verbose = 0)\n",
    "results[\"Train Accuracy\"].append(acc)\n",
    "results[\"Train Loss\"].append(loss)\n",
    "results[\"Ratio\"].append(acc/(model.count_params()/100*1000))\n",
    "print(\"Train Accuracy: {:.4f}  Train Loss: {:.4f}\".format(acc,loss))\n",
    "(loss, acc) = model.evaluate(test_big, verbose = 0)\n",
    "results[\"Test Accuracy\"].append(acc)\n",
    "results[\"Test Loss\"].append(loss)\n",
    "print(\"Test Accuracy: {:.4f}  Test Loss: {:.4f}\".format(acc,loss))\n",
    "results[\"Num. Params\"].append(model.count_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7 Kernel Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:tf.keras.mixed_precision.experimental.LossScaleOptimizer is deprecated. Please use tf.keras.mixed_precision.LossScaleOptimizer instead. Note that the non-experimental LossScaleOptimizer does not take a DynamicLossScale but instead takes the dynamic configuration directly in the constructor. For example:\n",
      "  opt = tf.keras.mixed_precision.LossScaleOptimizer(opt)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "N_CONV  = 4\n",
    "CONV = 256\n",
    "KERNEL = 7\n",
    "N_DENSE = 2\n",
    "DENSE = 1024\n",
    "DROPOUT = True\n",
    "BATCH_NORM = False\n",
    "MAX_POOLING = False\n",
    "idx = 17\n",
    "checkpoint = ModelCheckpoint(f'model_{idx}.h5', save_best_only=True, monitor='val_accuracy', mode='max', verbose=0)\n",
    "lr_reducer = ReduceLROnPlateau(monitor='val_accuracy', patience=10, factor=0.5, min_lr=1e-6, mode='max', verbose=1)\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "gc.collect()\n",
    "\n",
    "model = build_model(n_conv = N_CONV, kernel_size= KERNEL, conv = CONV, n_dense = N_DENSE, dense = DENSE, max_pool = MAX_POOLING, dropout = DROPOUT, batch_norm = BATCH_NORM, opt = \"adam\")\n",
    "if not f'model_{idx}.h5' in os.listdir(\".\"):\n",
    "    history = model.fit(train_big,steps_per_epoch=train_big.samples // BATCH_SIZE, epochs=100, validation_data=test_big, validation_steps=test_big.samples // BATCH_SIZE,  verbose = 0, callbacks=[checkpoint, lr_reducer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.8299  Train Loss: 0.5042\n",
      "Test Accuracy: 0.8290  Test Loss: 0.5557\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(f'model_{idx}.h5')\n",
    "title = \"{} Conv {} filters {} kernel size {} dense {} neurons with 0.2 Dropout on FC\".format(N_CONV, CONV, KERNEL, N_DENSE, DENSE)\n",
    "if not f'model_{idx}.h5' in os.listdir(\".\"):\n",
    "    plot_loss_accuracy(history, title)\n",
    "experiment.append(title)\n",
    "(loss, acc) = model.evaluate(train_big, verbose = 0)\n",
    "results[\"Train Accuracy\"].append(acc)\n",
    "results[\"Train Loss\"].append(loss)\n",
    "results[\"Ratio\"].append(acc/(model.count_params()/100*1000))\n",
    "print(\"Train Accuracy: {:.4f}  Train Loss: {:.4f}\".format(acc,loss))\n",
    "(loss, acc) = model.evaluate(test_big, verbose = 0)\n",
    "results[\"Test Accuracy\"].append(acc)\n",
    "results[\"Test Loss\"].append(loss)\n",
    "print(\"Test Accuracy: {:.4f}  Test Loss: {:.4f}\".format(acc,loss))\n",
    "results[\"Num. Params\"].append(model.count_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9 Kernel Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:tf.keras.mixed_precision.experimental.LossScaleOptimizer is deprecated. Please use tf.keras.mixed_precision.LossScaleOptimizer instead. Note that the non-experimental LossScaleOptimizer does not take a DynamicLossScale but instead takes the dynamic configuration directly in the constructor. For example:\n",
      "  opt = tf.keras.mixed_precision.LossScaleOptimizer(opt)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "N_CONV  = 4\n",
    "CONV = 256\n",
    "KERNEL = 9\n",
    "N_DENSE = 2\n",
    "DENSE = 1024\n",
    "DROPOUT = True\n",
    "BATCH_NORM = False\n",
    "MAX_POOLING = False\n",
    "idx = 18\n",
    "checkpoint = ModelCheckpoint(f'model_{idx}.h5', save_best_only=True, monitor='val_accuracy', mode='max', verbose=0)\n",
    "lr_reducer = ReduceLROnPlateau(monitor='val_accuracy', patience=10, factor=0.5, min_lr=1e-6, mode='max', verbose=1)\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "gc.collect()\n",
    "\n",
    "model = build_model(n_conv = N_CONV, kernel_size= KERNEL, conv = CONV, n_dense = N_DENSE, dense = DENSE, max_pool = MAX_POOLING, dropout = DROPOUT, batch_norm = BATCH_NORM, opt = \"adam\")\n",
    "if not f'model_{idx}.h5' in os.listdir(\".\"):\n",
    "    history = model.fit(train_big,steps_per_epoch=train_big.samples // BATCH_SIZE, epochs=100, validation_data=test_big, validation_steps=test_big.samples // BATCH_SIZE,  verbose = 0, callbacks=[checkpoint, lr_reducer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.7576  Train Loss: 0.6854\n",
      "Test Accuracy: 0.7633  Test Loss: 0.7265\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(f'model_{idx}.h5')\n",
    "title = \"{} Conv {} filters {} kernel size {} dense {} neurons with 0.2 Dropout on FC\".format(N_CONV, CONV, KERNEL, N_DENSE, DENSE)\n",
    "if not f'model_{idx}.h5' in os.listdir(\".\"):\n",
    "    plot_loss_accuracy(history, title)\n",
    "experiment.append(title)\n",
    "(loss, acc) = model.evaluate(train_big, verbose = 0)\n",
    "results[\"Train Accuracy\"].append(acc)\n",
    "results[\"Train Loss\"].append(loss)\n",
    "results[\"Ratio\"].append(acc/(model.count_params()/100*1000))\n",
    "print(\"Train Accuracy: {:.4f}  Train Loss: {:.4f}\".format(acc,loss))\n",
    "(loss, acc) = model.evaluate(test_big, verbose = 0)\n",
    "results[\"Test Accuracy\"].append(acc)\n",
    "results[\"Test Loss\"].append(loss)\n",
    "print(\"Test Accuracy: {:.4f}  Test Loss: {:.4f}\".format(acc,loss))\n",
    "results[\"Num. Params\"].append(model.count_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Model Similar to Literature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def block(conv, n_filters, n_conv):\n",
    "    for _ in range(n_conv):\n",
    "        conv = Conv2D(n_filters, (3,3), padding = \"same\", activation = \"relu\")(conv)\n",
    "    \n",
    "    conv = MaxPooling2D((2,2), strides=(2,2))(conv)\n",
    "    \n",
    "    return conv\n",
    "\n",
    "def build_block_model():\n",
    "    # Input\n",
    "    visible = Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n",
    "    \n",
    "    # Features\n",
    "    layer = block(visible, 64, 2)\n",
    "    layer = block(layer, 128, 2)\n",
    "    layer = block(layer, 256, 4)\n",
    "    \n",
    "    # Prediction\n",
    "    x = GlobalAveragePooling2D()(layer)\n",
    "    x = Dense(4096, activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(4096, activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(1000, activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    pred = Dense(len(CLASSES), activation='softmax')(x)\n",
    "    \n",
    "    # Final model\n",
    "    model = Model(inputs=visible, outputs=pred)\n",
    "    model.compile(optimizer=\"adam\", loss='categorical_crossentropy',metrics=[\"accuracy\"])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: ./datasets/MIT_split\n",
      "Found 1881 images belonging to 8 classes.\n",
      "Found 807 images belonging to 8 classes.\n",
      "WARNING:tensorflow:tf.keras.mixed_precision.experimental.LossScaleOptimizer is deprecated. Please use tf.keras.mixed_precision.LossScaleOptimizer instead. Note that the non-experimental LossScaleOptimizer does not take a DynamicLossScale but instead takes the dynamic configuration directly in the constructor. For example:\n",
      "  opt = tf.keras.mixed_precision.LossScaleOptimizer(opt)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = 64\n",
    "idx = 19\n",
    "checkpoint = ModelCheckpoint(f'model_{idx}.h5', save_best_only=True, monitor='val_accuracy', mode='max', verbose=0)\n",
    "lr_reducer = ReduceLROnPlateau(monitor='val_accuracy', patience=10, factor=0.5, min_lr=1e-6, mode='max', verbose=1)\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "gc.collect()\n",
    "\n",
    "train_big, test_big = get_dataset(DATA_DIR_BIG, aug = True)\n",
    "model = build_block_model()\n",
    "if not f'model_{idx}.h5' in os.listdir(\".\"):\n",
    "    history = model.fit(train_big,steps_per_epoch=train_big.samples // BATCH_SIZE, epochs=100, validation_data=test_big, validation_steps=test_big.samples // BATCH_SIZE, callbacks=[checkpoint, lr_reducer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.9522  Train Loss: 0.1410\n",
      "Test Accuracy: 0.8786  Test Loss: 0.4595\n",
      "Ration: 3.924048433857002e-09 \n"
     ]
    }
   ],
   "source": [
    "model.load_weights(f'model_{idx}.h5')\n",
    "title = \"3 VGGish Blocks with 0.2 Dropout\"\n",
    "if not f'model_{idx}.h5' in os.listdir(\".\"):\n",
    "    plot_loss_accuracy(history, title)\n",
    "experiment.append(title)\n",
    "(loss, acc) = model.evaluate(train_big, verbose = 0)\n",
    "results[\"Train Accuracy\"].append(acc)\n",
    "results[\"Train Loss\"].append(loss)\n",
    "results[\"Ratio\"].append(acc/(model.count_params()/100*1000))\n",
    "print(\"Train Accuracy: {:.4f}  Train Loss: {:.4f}\".format(acc,loss))\n",
    "(loss, acc) = model.evaluate(test_big, verbose = 0)\n",
    "results[\"Test Accuracy\"].append(acc)\n",
    "results[\"Test Loss\"].append(loss)\n",
    "print(\"Test Accuracy: {:.4f}  Test Loss: {:.4f}\".format(acc,loss))\n",
    "print(\"Ration: {} \".format(results[\"Ratio\"][-1]))\n",
    "results[\"Num. Params\"].append(model.count_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarizing all the experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Train Loss</th>\n",
       "      <th>Test Loss</th>\n",
       "      <th>Num. Params</th>\n",
       "      <th>Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1 Conv 64 filters 5 kernel size 1 dense 1024 neurons</th>\n",
       "      <td>Model 0</td>\n",
       "      <td>0.613503</td>\n",
       "      <td>0.655514</td>\n",
       "      <td>1.075764</td>\n",
       "      <td>1.001122</td>\n",
       "      <td>79624</td>\n",
       "      <td>7.705007e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2 Conv 64 filters 5 kernel size 1 dense 1024 neurons</th>\n",
       "      <td>Model 1</td>\n",
       "      <td>0.736310</td>\n",
       "      <td>0.774473</td>\n",
       "      <td>0.741201</td>\n",
       "      <td>0.683470</td>\n",
       "      <td>182088</td>\n",
       "      <td>4.043707e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4 Conv 64 filters 5 kernel size 1 dense 1024 neurons</th>\n",
       "      <td>Model 2</td>\n",
       "      <td>0.856991</td>\n",
       "      <td>0.850062</td>\n",
       "      <td>0.419730</td>\n",
       "      <td>0.494306</td>\n",
       "      <td>387016</td>\n",
       "      <td>2.214355e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8 Conv 64 filters 5 kernel size 1 dense 1024 neurons</th>\n",
       "      <td>Model 3</td>\n",
       "      <td>0.867092</td>\n",
       "      <td>0.842627</td>\n",
       "      <td>0.386379</td>\n",
       "      <td>0.490809</td>\n",
       "      <td>796872</td>\n",
       "      <td>1.088119e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4 Conv 64 filters 5 kernel size 2 dense 1024 neurons</th>\n",
       "      <td>Model 4</td>\n",
       "      <td>0.897395</td>\n",
       "      <td>0.853779</td>\n",
       "      <td>0.303307</td>\n",
       "      <td>0.460579</td>\n",
       "      <td>1436616</td>\n",
       "      <td>6.246589e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4 Conv 64 filters 5 kernel size 4 dense 1024 neurons</th>\n",
       "      <td>Model 5</td>\n",
       "      <td>0.897927</td>\n",
       "      <td>0.868649</td>\n",
       "      <td>0.305947</td>\n",
       "      <td>0.442636</td>\n",
       "      <td>3535816</td>\n",
       "      <td>2.539517e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4 Conv 32 filters 5 kernel size 2 dense 1024 neurons</th>\n",
       "      <td>Model 6</td>\n",
       "      <td>0.862307</td>\n",
       "      <td>0.843866</td>\n",
       "      <td>0.408355</td>\n",
       "      <td>0.513012</td>\n",
       "      <td>1170920</td>\n",
       "      <td>7.364357e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4 Conv 128 filters 5 kernel size 2 dense 1024 neurons</th>\n",
       "      <td>Model 7</td>\n",
       "      <td>0.883041</td>\n",
       "      <td>0.862454</td>\n",
       "      <td>0.315263</td>\n",
       "      <td>0.407398</td>\n",
       "      <td>2428808</td>\n",
       "      <td>3.635697e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4 Conv 256 filters 5 kernel size 2 dense 1024 neurons</th>\n",
       "      <td>Model 8</td>\n",
       "      <td>0.870282</td>\n",
       "      <td>0.846344</td>\n",
       "      <td>0.382219</td>\n",
       "      <td>0.477707</td>\n",
       "      <td>6256392</td>\n",
       "      <td>1.391028e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4 Conv 256 filters 5 kernel size 2 dense 1024 neurons with MaxPooling</th>\n",
       "      <td>Model 9</td>\n",
       "      <td>0.920255</td>\n",
       "      <td>0.863693</td>\n",
       "      <td>0.223434</td>\n",
       "      <td>0.507280</td>\n",
       "      <td>6256392</td>\n",
       "      <td>1.470904e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4 Conv 256 filters 5 kernel size 2 dense 1024 neurons with 0.2 Dropout on FC</th>\n",
       "      <td>Model 10</td>\n",
       "      <td>0.886231</td>\n",
       "      <td>0.861214</td>\n",
       "      <td>0.303123</td>\n",
       "      <td>0.437434</td>\n",
       "      <td>6256392</td>\n",
       "      <td>1.416520e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4 Conv 256 filters 5 kernel size 2 dense 1024 neurons with BatchNorm</th>\n",
       "      <td>Model 11</td>\n",
       "      <td>0.987241</td>\n",
       "      <td>0.878563</td>\n",
       "      <td>0.061328</td>\n",
       "      <td>0.440767</td>\n",
       "      <td>6268680</td>\n",
       "      <td>1.574878e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Conv 4 filters 256 kernel size 5 dense 2 neurons with MaxPooling and Dropout</th>\n",
       "      <td>Model 12</td>\n",
       "      <td>0.926635</td>\n",
       "      <td>0.867410</td>\n",
       "      <td>0.196407</td>\n",
       "      <td>0.408125</td>\n",
       "      <td>6256392</td>\n",
       "      <td>1.481101e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4 Conv 256 filters 5 kernel size 2 dense 1024 neurons with MaxPooling and BatchNorm</th>\n",
       "      <td>Model 13</td>\n",
       "      <td>0.970229</td>\n",
       "      <td>0.887237</td>\n",
       "      <td>0.102440</td>\n",
       "      <td>0.398179</td>\n",
       "      <td>6268680</td>\n",
       "      <td>1.547740e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4 Conv 256 filters 5 kernel size 2 dense 1024 neurons with MaxPooling and Dropout</th>\n",
       "      <td>Model 14</td>\n",
       "      <td>0.922382</td>\n",
       "      <td>0.864932</td>\n",
       "      <td>0.226596</td>\n",
       "      <td>0.437865</td>\n",
       "      <td>6256392</td>\n",
       "      <td>1.474303e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4 Conv 256 filters 5 kernel size 2 dense 1024 neurons with BatchNorm, MaxPooling and Dropout</th>\n",
       "      <td>Model 15</td>\n",
       "      <td>0.960128</td>\n",
       "      <td>0.889715</td>\n",
       "      <td>0.127559</td>\n",
       "      <td>0.357219</td>\n",
       "      <td>6268680</td>\n",
       "      <td>1.531626e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4 Conv 256 filters 3 kernel size 2 dense 1024 neurons with 0.2 Dropout on FC</th>\n",
       "      <td>Model 16</td>\n",
       "      <td>0.899522</td>\n",
       "      <td>0.843866</td>\n",
       "      <td>0.301340</td>\n",
       "      <td>0.504453</td>\n",
       "      <td>3098376</td>\n",
       "      <td>2.903203e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4 Conv 256 filters 7 kernel size 2 dense 1024 neurons with 0.2 Dropout on FC</th>\n",
       "      <td>Model 17</td>\n",
       "      <td>0.829878</td>\n",
       "      <td>0.828996</td>\n",
       "      <td>0.504232</td>\n",
       "      <td>0.555701</td>\n",
       "      <td>10993416</td>\n",
       "      <td>7.548861e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4 Conv 256 filters 9 kernel size 2 dense 1024 neurons with 0.2 Dropout on FC</th>\n",
       "      <td>Model 18</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.763321</td>\n",
       "      <td>0.685415</td>\n",
       "      <td>0.726474</td>\n",
       "      <td>17309448</td>\n",
       "      <td>4.376660e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3 VGGish Blocks with 0.2 Dropout</th>\n",
       "      <td>Model 19</td>\n",
       "      <td>0.952153</td>\n",
       "      <td>0.878563</td>\n",
       "      <td>0.141014</td>\n",
       "      <td>0.459521</td>\n",
       "      <td>24264560</td>\n",
       "      <td>3.924048e-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       Model  Train Accuracy  \\\n",
       "1 Conv 64 filters 5 kernel size 1 dense 1024 ne...   Model 0        0.613503   \n",
       "2 Conv 64 filters 5 kernel size 1 dense 1024 ne...   Model 1        0.736310   \n",
       "4 Conv 64 filters 5 kernel size 1 dense 1024 ne...   Model 2        0.856991   \n",
       "8 Conv 64 filters 5 kernel size 1 dense 1024 ne...   Model 3        0.867092   \n",
       "4 Conv 64 filters 5 kernel size 2 dense 1024 ne...   Model 4        0.897395   \n",
       "4 Conv 64 filters 5 kernel size 4 dense 1024 ne...   Model 5        0.897927   \n",
       "4 Conv 32 filters 5 kernel size 2 dense 1024 ne...   Model 6        0.862307   \n",
       "4 Conv 128 filters 5 kernel size 2 dense 1024 n...   Model 7        0.883041   \n",
       "4 Conv 256 filters 5 kernel size 2 dense 1024 n...   Model 8        0.870282   \n",
       "4 Conv 256 filters 5 kernel size 2 dense 1024 n...   Model 9        0.920255   \n",
       "4 Conv 256 filters 5 kernel size 2 dense 1024 n...  Model 10        0.886231   \n",
       "4 Conv 256 filters 5 kernel size 2 dense 1024 n...  Model 11        0.987241   \n",
       "Conv 4 filters 256 kernel size 5 dense 2 neuron...  Model 12        0.926635   \n",
       "4 Conv 256 filters 5 kernel size 2 dense 1024 n...  Model 13        0.970229   \n",
       "4 Conv 256 filters 5 kernel size 2 dense 1024 n...  Model 14        0.922382   \n",
       "4 Conv 256 filters 5 kernel size 2 dense 1024 n...  Model 15        0.960128   \n",
       "4 Conv 256 filters 3 kernel size 2 dense 1024 n...  Model 16        0.899522   \n",
       "4 Conv 256 filters 7 kernel size 2 dense 1024 n...  Model 17        0.829878   \n",
       "4 Conv 256 filters 9 kernel size 2 dense 1024 n...  Model 18        0.757576   \n",
       "3 VGGish Blocks with 0.2 Dropout                    Model 19        0.952153   \n",
       "\n",
       "                                                    Test Accuracy  Train Loss  \\\n",
       "1 Conv 64 filters 5 kernel size 1 dense 1024 ne...       0.655514    1.075764   \n",
       "2 Conv 64 filters 5 kernel size 1 dense 1024 ne...       0.774473    0.741201   \n",
       "4 Conv 64 filters 5 kernel size 1 dense 1024 ne...       0.850062    0.419730   \n",
       "8 Conv 64 filters 5 kernel size 1 dense 1024 ne...       0.842627    0.386379   \n",
       "4 Conv 64 filters 5 kernel size 2 dense 1024 ne...       0.853779    0.303307   \n",
       "4 Conv 64 filters 5 kernel size 4 dense 1024 ne...       0.868649    0.305947   \n",
       "4 Conv 32 filters 5 kernel size 2 dense 1024 ne...       0.843866    0.408355   \n",
       "4 Conv 128 filters 5 kernel size 2 dense 1024 n...       0.862454    0.315263   \n",
       "4 Conv 256 filters 5 kernel size 2 dense 1024 n...       0.846344    0.382219   \n",
       "4 Conv 256 filters 5 kernel size 2 dense 1024 n...       0.863693    0.223434   \n",
       "4 Conv 256 filters 5 kernel size 2 dense 1024 n...       0.861214    0.303123   \n",
       "4 Conv 256 filters 5 kernel size 2 dense 1024 n...       0.878563    0.061328   \n",
       "Conv 4 filters 256 kernel size 5 dense 2 neuron...       0.867410    0.196407   \n",
       "4 Conv 256 filters 5 kernel size 2 dense 1024 n...       0.887237    0.102440   \n",
       "4 Conv 256 filters 5 kernel size 2 dense 1024 n...       0.864932    0.226596   \n",
       "4 Conv 256 filters 5 kernel size 2 dense 1024 n...       0.889715    0.127559   \n",
       "4 Conv 256 filters 3 kernel size 2 dense 1024 n...       0.843866    0.301340   \n",
       "4 Conv 256 filters 7 kernel size 2 dense 1024 n...       0.828996    0.504232   \n",
       "4 Conv 256 filters 9 kernel size 2 dense 1024 n...       0.763321    0.685415   \n",
       "3 VGGish Blocks with 0.2 Dropout                         0.878563    0.141014   \n",
       "\n",
       "                                                    Test Loss  Num. Params  \\\n",
       "1 Conv 64 filters 5 kernel size 1 dense 1024 ne...   1.001122        79624   \n",
       "2 Conv 64 filters 5 kernel size 1 dense 1024 ne...   0.683470       182088   \n",
       "4 Conv 64 filters 5 kernel size 1 dense 1024 ne...   0.494306       387016   \n",
       "8 Conv 64 filters 5 kernel size 1 dense 1024 ne...   0.490809       796872   \n",
       "4 Conv 64 filters 5 kernel size 2 dense 1024 ne...   0.460579      1436616   \n",
       "4 Conv 64 filters 5 kernel size 4 dense 1024 ne...   0.442636      3535816   \n",
       "4 Conv 32 filters 5 kernel size 2 dense 1024 ne...   0.513012      1170920   \n",
       "4 Conv 128 filters 5 kernel size 2 dense 1024 n...   0.407398      2428808   \n",
       "4 Conv 256 filters 5 kernel size 2 dense 1024 n...   0.477707      6256392   \n",
       "4 Conv 256 filters 5 kernel size 2 dense 1024 n...   0.507280      6256392   \n",
       "4 Conv 256 filters 5 kernel size 2 dense 1024 n...   0.437434      6256392   \n",
       "4 Conv 256 filters 5 kernel size 2 dense 1024 n...   0.440767      6268680   \n",
       "Conv 4 filters 256 kernel size 5 dense 2 neuron...   0.408125      6256392   \n",
       "4 Conv 256 filters 5 kernel size 2 dense 1024 n...   0.398179      6268680   \n",
       "4 Conv 256 filters 5 kernel size 2 dense 1024 n...   0.437865      6256392   \n",
       "4 Conv 256 filters 5 kernel size 2 dense 1024 n...   0.357219      6268680   \n",
       "4 Conv 256 filters 3 kernel size 2 dense 1024 n...   0.504453      3098376   \n",
       "4 Conv 256 filters 7 kernel size 2 dense 1024 n...   0.555701     10993416   \n",
       "4 Conv 256 filters 9 kernel size 2 dense 1024 n...   0.726474     17309448   \n",
       "3 VGGish Blocks with 0.2 Dropout                     0.459521     24264560   \n",
       "\n",
       "                                                           Ratio  \n",
       "1 Conv 64 filters 5 kernel size 1 dense 1024 ne...  7.705007e-07  \n",
       "2 Conv 64 filters 5 kernel size 1 dense 1024 ne...  4.043707e-07  \n",
       "4 Conv 64 filters 5 kernel size 1 dense 1024 ne...  2.214355e-07  \n",
       "8 Conv 64 filters 5 kernel size 1 dense 1024 ne...  1.088119e-07  \n",
       "4 Conv 64 filters 5 kernel size 2 dense 1024 ne...  6.246589e-08  \n",
       "4 Conv 64 filters 5 kernel size 4 dense 1024 ne...  2.539517e-08  \n",
       "4 Conv 32 filters 5 kernel size 2 dense 1024 ne...  7.364357e-08  \n",
       "4 Conv 128 filters 5 kernel size 2 dense 1024 n...  3.635697e-08  \n",
       "4 Conv 256 filters 5 kernel size 2 dense 1024 n...  1.391028e-08  \n",
       "4 Conv 256 filters 5 kernel size 2 dense 1024 n...  1.470904e-08  \n",
       "4 Conv 256 filters 5 kernel size 2 dense 1024 n...  1.416520e-08  \n",
       "4 Conv 256 filters 5 kernel size 2 dense 1024 n...  1.574878e-08  \n",
       "Conv 4 filters 256 kernel size 5 dense 2 neuron...  1.481101e-08  \n",
       "4 Conv 256 filters 5 kernel size 2 dense 1024 n...  1.547740e-08  \n",
       "4 Conv 256 filters 5 kernel size 2 dense 1024 n...  1.474303e-08  \n",
       "4 Conv 256 filters 5 kernel size 2 dense 1024 n...  1.531626e-08  \n",
       "4 Conv 256 filters 3 kernel size 2 dense 1024 n...  2.903203e-08  \n",
       "4 Conv 256 filters 7 kernel size 2 dense 1024 n...  7.548861e-09  \n",
       "4 Conv 256 filters 9 kernel size 2 dense 1024 n...  4.376660e-09  \n",
       "3 VGGish Blocks with 0.2 Dropout                    3.924048e-09  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame.from_dict(results)\n",
    "df.index = experiment\n",
    "df[\"Model\"] = [\"Model {}\".format(i) for i in range(len(experiment))]\n",
    "df[[\"Model\",\"Train Accuracy\", \"Test Accuracy\", \"Train Loss\", \"Test Loss\", \"Num. Params\", \"Ratio\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1080x1080 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(nrows=2, ncols=2)\n",
    "x = 0\n",
    "#fig.subplots_adjust(hspace=1)\n",
    "cols = list(df.columns)\n",
    "cols.remove(\"Ratio\")\n",
    "cols.remove(\"Model\")\n",
    "cols.remove(\"Num. Params\")\n",
    "\n",
    "for i, col in enumerate(cols):\n",
    "    c = df[col]\n",
    "    if \"Accuracy\" in col:\n",
    "        colors = [\"r\" if val == np.max(c) else \"b\" for val in c]\n",
    "    else:\n",
    "        colors = [\"r\" if val == np.min(c) else \"b\" for val in c]\n",
    "        \n",
    "    if i == 2:\n",
    "        x = 1\n",
    "    i = i % 2\n",
    "            \n",
    "    c.plot(kind=\"bar\", figsize=(15,15), title=col, ax=axes[x,i], color=colors)\n",
    "    axes[x,i].set_xticklabels(df[\"Model\"], rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x1008 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = df.plot.scatter(y = \"Train Accuracy\", x = \"Num. Params\", figsize=(12,14), color=[\"r\" for _ in range(len(df))], s=50)\n",
    "for i, j in enumerate(df.index):\n",
    "    ax.annotate(\"Model {}\".format(i), (df[\"Num. Params\"][i], df[\"Train Accuracy\"][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fae8b896b010e7d5e6a5cd073aabec8a3c653cb61b068cf7cdb629a6903a157a"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
